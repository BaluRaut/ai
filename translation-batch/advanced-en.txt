Exception Handling Mastery
Master error handling and exception management
Exception handling is crucial for writing robust programs that can gracefully handle errors. Python uses try/except blocks to catch and handle exceptions, allowing programs to recover from errors instead of crashing. Understanding exception handling improves code reliability and user experience.
Exceptions are errors detected during execution
try/except blocks catch and handle exceptions
finally block always executes for cleanup
else block runs if no exception occurs
Can raise custom exceptions for specific errors
File Operations
Handle file not found, permission errors
Try to open file, handle if missing or inaccessible
Network Requests
Handle connection failures, timeouts
API calls with retry logic on failures
User Input Validation
Catch invalid input formats
Convert string to int, handle ValueError
Database Operations
Handle connection errors, query failures
Rollback transactions on errors
Catch specific exceptions, not generic Exception
Use finally for cleanup (close files, connections)
Provide meaningful error messages
Log exceptions for debugging
Raise exceptions for invalid states
Don't use bare except: (catches everything including sys.exit)
Don't silently ignore exceptions
Don't use exceptions for flow control
Don't catch exceptions you can't handle
Don't forget to clean up resources
Catch specific exceptions first, general ones last
Use context managers (with) for automatic cleanup
Create custom exceptions for domain-specific errors
Document what exceptions functions can raise
Fail fast - detect errors early
Basic Exception Handling
try/except blocks catch exceptions. Catch specific exceptions when possible
try/except/else/finally
else runs if no exception, finally always runs for cleanup. Context managers are preferred
Raising Exceptions
Raise exceptions to signal errors. Use specific exception types for clarity
Custom Exceptions
Custom exceptions provide domain-specific error handling with meaningful names
Real-World: Robust File Processor
Comprehensive error handling makes programs robust and user-friendly
File Handling & I/O Operations
Master file operations and data persistence
File handling is essential for reading and writing data to disk. Python provides powerful tools for working with files, including context managers for safe operations, pathlib for path manipulation, and built-in support for common formats like CSV and JSON. Understanding file I/O is crucial for data persistence and processing.
Use context managers (with) for automatic file closing
Different modes: read (r), write (w), append (a), binary (b)
pathlib provides object-oriented path handling
CSV and JSON modules for structured data
Always handle file-related exceptions
Data Persistence
Save and load application data
Save user preferences, game state, application config
Data Processing
Read, transform, and write data files
Process CSV reports, analyze log files, data ETL
Configuration Management
Load settings from config files
Read JSON/YAML config, environment variables
Data Export/Import
Exchange data with other systems
Export to CSV/Excel, import from JSON/XML
Always use context managers (with) for file operations
Handle exceptions (FileNotFoundError, PermissionError)
Close files explicitly if not using with statement
Use pathlib for cross-platform path handling
Specify encoding explicitly (usually utf-8)
Don't forget to close files (use with)
Don't read entire large files into memory
Don't ignore file operation exceptions
Don't use string concatenation for paths
Don't assume file exists without checking
Use pathlib.Path for path operations
Always specify file encoding
Process large files in chunks or lines
Use appropriate modules (csv, json) for structured data
Validate paths and permissions before operations
Basic File Operations
Context managers (with) ensure files are properly closed even if errors occur
Path Handling with pathlib
pathlib provides clean, object-oriented path handling that works across platforms
Working with CSV Files
CSV module handles comma-separated values with automatic quoting and escaping
Working with JSON Files
JSON module provides easy conversion between Python objects and JSON format
Real-World: Log File Analyzer
Real-world example combining file reading, analysis, and JSON export
Modules & Packages
Master code organization and imports
Modules and packages are Python's way of organizing code into reusable components. A module is a single Python file, while a package is a collection of modules. Understanding imports, the module search path, and package structure is essential for building maintainable applications and reusing code effectively.
Modules are single .py files containing Python code
Packages are directories containing __init__.py
import statement loads modules and packages
__name__ == "__main__" identifies script entry point
Python searches sys.path for modules
Code Organization
Split large projects into manageable files
utils.py, models.py, views.py, config.py
Code Reuse
Share code across multiple scripts
Common utilities, helper functions, constants
Library Development
Create reusable libraries
Create installable packages with setup.py
Namespace Management
Avoid naming conflicts
myapp.database, myapp.api, myapp.utils
Use meaningful module and package names
Keep modules focused (single responsibility)
Use __init__.py for package initialization
Import only what you need
Use if __name__ == "__main__" for scripts
Don't use circular imports
Don't import * (use explicit imports)
Don't pollute global namespace
Don't modify sys.path unless necessary
Don't forget __init__.py for packages
Use absolute imports in packages
Keep __init__.py minimal
Group imports: stdlib, third-party, local
Use importlib for dynamic imports
Document module purpose in docstring
Creating and Importing Modules
Multiple ways to import modules. Use explicit imports for clarity
Creating Packages
Packages organize related modules. __init__.py makes directory a package
Script vs Module: __name__ == "__main__"
__name__ is "__main__" only when file is run as script, not when imported
Module Search Path and sys.path
sys.path determines where Python looks for modules. Usually no need to modify it
Real-World: Project Structure
Professional structure with clear separation of concerns and proper package organization
Object-Oriented Programming Basics
Master the 4 pillars of OOP: Encapsulation, Inheritance, Polymorphism, and Abstraction
Object-Oriented Programming (OOP) is a powerful programming paradigm that structures code around "objects" rather than functions and logic. These objects are instances of "classes", which act as blueprints. OOP relies on four fundamental pillars: Encapsulation (hiding internal state), Inheritance (creating new classes from existing ones), Polymorphism (using a unified interface for different types), and Abstraction (hiding complex implementation details). This approach makes code more modular, reusable, and easier to maintain for large-scale applications.
Classes are blueprints defining attributes (data) and methods (behavior)
Objects are concrete instances created from classes
The 4 Pillars of OOP: Encapsulation, Inheritance, Polymorphism, Abstraction
Encapsulation protects data using private attributes and properties
Inheritance promotes code reuse by deriving child classes from parents
Polymorphism allows different classes to be treated as instances of the same general class
Abstraction hides complex reality while exposing only the necessary parts
Composition (has-a relationship) is often preferred over Inheritance (is-a relationship)
Modeling Real-World Entities
Represent complex entities with attributes and behaviors
Car class with attributes (color, model) and methods (start, stop)
Code Organization
Group related functionality together
User class with authentication, profile methods
Code Reuse
Inherit common functionality
Animal base class, Dog and Cat inherit behaviors
Large Applications
Structure complex systems
E-commerce: Product, Cart, Order, Payment classes
Use classes to model real-world concepts
Keep class responsibilities focused (Single Responsibility)
Use inheritance for "is-a" relationships
Make attributes private when they shouldn't be accessed directly
Provide clear class and method names
Don't create god classes that do everything
Don't use inheritance just for code reuse (use composition)
Don't expose internal implementation details
Don't forget to call super().__init__() in child classes
Don't overuse inheritance (deep hierarchies are hard to maintain)
Favor composition over inheritance
Use properties for controlled attribute access
Implement __str__ and __repr__ for readable objects
Follow naming conventions (CapWords for classes)
Document classes and their public interface
1. Creating Classes and Objects
Classes define the structure. __init__ initializes objects. self refers to the instance. Create objects by calling the class.
2. Encapsulation and Properties
Use __ prefix for private attributes. @property creates managed attributes with getters/setters for validation.
3. Inheritance
Inheritance allows child classes to reuse parent code. Use super() to call parent methods. Override methods to customize behavior.
4. Polymorphism
Polymorphism allows different classes to be treated as instances of the same general class through a common interface.
5. Abstraction (Abstract Base Classes)
Abstraction hides complex implementation details. Abstract Base Classes (ABC) enforce that child classes implement specific methods.
6. Magic Methods (Operator Overloading)
Magic methods (dunder methods) allow you to define how objects behave with built-in operations like printing, addition, and comparison.
Advanced OOP Concepts
Deep dive into Python object model, MRO, and Metaclasses
Advanced Object-Oriented Programming in Python goes beyond basic classes and inheritance. It involves understanding how Python actually implements objects, how method resolution works in multiple inheritance, how to optimize memory usage, and how to customize class creation itself using metaclasses.
Multiple Inheritance allows a class to inherit from multiple parents
MRO (Method Resolution Order) determines the order of class search
Mixins are small classes that provide specific functionality
__slots__ optimizes memory usage by preventing dynamic attribute creation
Descriptors allow customizing attribute access (get/set/delete)
Metaclasses are "classes of classes" that control class creation
Complex Class Hierarchies
Using multiple inheritance and mixins
Django Mixins (LoginRequiredMixin, PermissionRequiredMixin)
Memory Optimization
Handling millions of small objects
Using __slots__ for Point or Particle classes
Framework Development
Creating APIs and ORMs
Django models, SQLAlchemy declarative base (Metaclasses)
Resource Management
Custom context managers
Database connections, file locks using __enter__/__exit__
Use Mixins to share functionality without deep hierarchies
Use super() for cooperative multiple inheritance
Use __slots__ only when memory is a critical bottleneck
Use descriptors for reusable attribute logic
Keep metaclasses for framework-level code
Don't create complex diamond inheritance structures if avoidable
Don't use __slots__ if you need dynamic attributes
Don't overuse metaclasses (they are "magic")
Don't rely on MRO for logic (it can be confusing)
Don't mix classic and new-style classes (Python 2 legacy)
Follow the C3 linearization algorithm (MRO)
Prefer composition over complex multiple inheritance
Document mixin requirements clearly
Use abstract base classes to define interfaces
Test MRO with help(Class) to verify order
1. Multiple Inheritance and MRO
Python uses C3 linearization for MRO. super() ensures each class in the hierarchy is called exactly once.
2. Memory Optimization with __slots__
__slots__ saves memory by suppressing __dict__ creation, useful for creating millions of small objects.
3. Descriptors
Descriptors allow you to define reusable behavior for attribute access (get, set, delete) across multiple classes.
4. Context Managers as Classes
Implementing __enter__ and __exit__ allows classes to be used with the "with" statement for resource management.
Async/Await & Concurrency
Master asynchronous programming for I/O-bound operations
Asynchronous programming allows your program to perform other tasks while waiting for I/O operations (network requests, file operations, database queries). Python's async/await syntax makes concurrent programming more readable and efficient.

**Key Concepts:**

- **async/await**: Define and call asynchronous functions
- **Event Loop**: Manages execution of async tasks
- **Coroutines**: Functions that can pause and resume
- **Tasks**: Wrapped coroutines that run concurrently
- **asyncio**: Python's async programming library

**When to Use:**

Use async/await for I/O-bound operations (network, files, databases). For CPU-bound tasks, use multiprocessing instead.
async def creates a coroutine function
await pauses execution until the awaited task completes
Event loop manages concurrent execution
asyncio.gather() runs multiple tasks concurrently
asyncio.create_task() schedules a coroutine to run
Use for I/O-bound operations, not CPU-bound
Async functions must be awaited or scheduled
Libraries must support async (aiohttp, asyncpg, etc.)
Web Scraping
Fetch multiple URLs concurrently
Download 100 web pages in parallel instead of sequentially
API Requests
Make multiple API calls simultaneously
Fetch data from 10 different APIs at once
Database Queries
Run multiple queries concurrently
Query multiple tables in parallel with asyncpg
Real-time Applications
Handle multiple connections simultaneously
WebSocket server managing thousands of connections
Use async/await for I/O-bound operations
Always await async functions
Use asyncio.gather() to run tasks concurrently
Handle exceptions in async code properly
Use async context managers (async with)
Use async libraries (aiohttp, not requests)
Don't use async for CPU-bound tasks
Don't block the event loop with synchronous code
Don't forget to await async functions
Don't mix sync and async code without care
Don't use time.sleep() (use asyncio.sleep())
Don't create too many concurrent tasks without limits
Use asyncio.run() to start the event loop
Create tasks with asyncio.create_task() for concurrent execution
Use asyncio.gather() to wait for multiple tasks
Implement timeouts with asyncio.wait_for()
Use semaphores to limit concurrent operations
Handle cancellation with try/except asyncio.CancelledError
Profile async code to ensure it's actually faster
Basic Async/Await
Define and call asynchronous functions. async def creates a coroutine, await pauses until completion.
Concurrent API Requests
Fetch multiple URLs concurrently. Much faster than sequential requests for I/O-bound operations.
Error Handling & Timeouts
Handle errors and timeouts in async code. Use try/except and asyncio.wait_for() for robustness.
Rate Limiting with Semaphores
Control concurrent operations with semaphores to avoid overwhelming resources (APIs, databases, network).
Context Managers
Master resource management with context managers
Context managers ensure resources are properly acquired and released, even if errors occur. They implement the "with" statement protocol using __enter__ and __exit__ methods or the contextlib module.

**What They Solve:**

- Automatic resource cleanup (files, locks, connections)
- Exception-safe resource handling
- Clean, readable resource management code

**Two Ways to Create:**

1. **Class-based**: Implement __enter__ and __exit__
2. **Decorator-based**: Use @contextmanager decorator
Context managers guarantee cleanup even if exceptions occur
__enter__ acquires the resource and returns it
__exit__ releases the resource, receives exception info
@contextmanager decorator simplifies creation
Use "with" statement to invoke context managers
Common for files, locks, database connections
Can suppress exceptions by returning True from __exit__
Supports async with async context managers
File Handling
Automatically close files even if errors occur
with open("file.txt") as f: ensures file closes
Database Connections
Commit transactions and close connections properly
with db.transaction(): commits on success, rollback on error
Thread Locks
Acquire and release locks safely
with lock: automatically releases lock
Temporary State
Change and restore state temporarily
with temp_directory(): creates and cleans up temp dir
Always use context managers for resource management
Implement proper cleanup in __exit__
Use contextlib for simple cases
Handle exceptions appropriately in __exit__
Document what resources are managed
Test that cleanup happens on exceptions
Don't forget to return the resource from __enter__
Don't raise exceptions in __exit__ unless necessary
Don't rely on __del__ for cleanup
Don't leave resources open on exceptions
Don't create context managers that do too much
Don't suppress exceptions without good reason
Prefer context managers over try/finally
Use @contextmanager for simple cases
Return resource from __enter__ for "as" clause
__exit__ should return False to propagate exceptions
Support both sync and async when appropriate
Make context managers reusable when possible
Document the managed resource lifecycle
Class-based Context Manager
Implement __enter__ and __exit__ to create a context manager. __enter__ sets up resources, __exit__ cleans up.
@contextmanager Decorator
Use @contextmanager for simpler context managers. Yield the resource, cleanup happens after yield.
Multiple Context Managers
Use multiple context managers in a single with statement for managing multiple resources.
Async Context Managers
Use async with for async context managers. Implement __aenter__ and __aexit__ or use @asynccontextmanager.
Iterators & Iterables
Master iteration protocols and create custom iterators
Iterators and iterables are fundamental to Python's for loops, comprehensions, and many built-in functions. Understanding them allows you to create memory-efficient, custom iteration logic.

**Key Distinctions:**

- **Iterable**: Any object that can return an iterator (__iter__ method)
- **Iterator**: Object that produces values one at a time (__next__ method)
- **Generator**: Special iterator created with yield

**When to Use:**

- Processing large datasets that don't fit in memory
- Creating custom iteration logic
- Lazy evaluation for performance
- Infinite sequences
Iterables have __iter__() returning an iterator
Iterators have __next__() returning next value
Iterators raise StopIteration when exhausted
Generators are iterators created with yield
iter() converts iterables to iterators
Iterators can only be traversed once
Iterables can be iterated multiple times
Many built-ins accept iterables (sum, max, list, etc.)
Large File Processing
Read files line-by-line without loading entire file
Process 10GB log file with minimal memory
Database Result Sets
Fetch database records one at a time
Iterate through millions of database rows efficiently
Custom Data Structures
Make custom classes work with for loops
Tree traversal, linked list iteration, graph exploration
Infinite Sequences
Generate values on-demand indefinitely
Fibonacci numbers, timestamps, IDs
Implement __iter__ and __next__ for custom iterators
Raise StopIteration when iteration completes
Use generators for simple iteration logic
Prefer iterators for memory-efficient processing
Use itertools for advanced iteration patterns
Make iterables reusable (return new iterator from __iter__)
Don't forget to raise StopIteration
Don't modify collection while iterating
Don't reuse exhausted iterators
Don't create iterators when lists would work fine
Don't forget __iter__ returns self for iterators
Don't use iterators for small datasets that fit in memory
Use generators (yield) instead of manual iterator classes when possible
Implement __iter__ to return self for iterator objects
Document if your iterator is single-use or reusable
Use itertools for combining/chaining iterators
Prefer iterators over loading all data into memory
Use next() with default to handle StopIteration gracefully
Make iterables reusable by creating new iterator each time
Iterator vs Iterable Basics
Understand the difference between iterables (have __iter__) and iterators (have __next__). Iterators are single-use.
Custom Iterator Class
Create custom iterator by implementing __iter__ (returns self) and __next__ (returns next value or raises StopIteration).
Generators - Simpler Iterators
Generators use yield to create iterators without manual __iter__/__next__ implementation. More concise and readable.
Itertools - Advanced Iteration
itertools module provides powerful tools for combining, filtering, and transforming iterators efficiently.
Metaclasses
Master Python's class creation mechanism and metaprogramming
Metaclasses are "classes of classes" - they define how classes behave. While rarely needed in everyday code, understanding metaclasses reveals Python's object model and enables powerful metaprogramming.

**What Are Metaclasses?**

- Classes are instances of metaclasses
- The default metaclass is `type`
- Metaclasses control class creation
- Used for frameworks, ORMs, validation, logging

**Key Insight:**

```python
# Everything is an object
isinstance(5, int)          # True
isinstance(int, type)       # True
isinstance(type, type)      # True (type is its own metaclass!)
```

**When to Use:**

Rarely! Use when you need to modify class creation itself (frameworks, ORMs, DSLs). For most cases, decorators, descriptors, or __init_subclass__ are simpler.
type is the default metaclass for all classes
Classes are instances of their metaclass
Metaclasses control class creation via __new__ and __init__
__init_subclass__ is simpler alternative for many use cases
Metaclasses inherit from type
Used in ORMs (SQLAlchemy), web frameworks (Django)
Very powerful but complex - use sparingly
Can validate class attributes at definition time
ORM Frameworks
Automatically register model classes
SQLAlchemy uses metaclasses to track database models
API Clients
Auto-generate methods from API spec
Create HTTP methods from API documentation
Singleton Pattern
Ensure only one instance of a class
Database connection, configuration manager
Validation
Validate class attributes at definition
Ensure required methods are implemented
Understand type() and how classes are created
Use __init_subclass__ before metaclasses when possible
Document metaclass behavior clearly
Keep metaclasses simple and focused
Use for framework-level code, not application code
Test metaclass behavior thoroughly
Don't use metaclasses when decorators would work
Don't overcomplicate class hierarchies
Don't use metaclasses for simple attribute validation
Don't forget __init_subclass__ exists (simpler alternative)
Don't create metaclasses without clear justification
Don't use multiple metaclasses (conflicts are complex)
Prefer __init_subclass__ over metaclasses for validation
Use class decorators for simple modifications
Document why metaclass is necessary
Inherit from type for custom metaclasses
Override __new__ to modify class creation
Use super() in metaclass methods
Keep metaclass logic minimal and clear
Understanding type() - The Meta metaclass
type() is both a function (returns type of object) and the default metaclass (creates classes). All classes are instances of type.
Custom Metaclass Basics
Create custom metaclass by inheriting from type. Override __new__ to modify class creation. Metaclass __new__ runs when class is defined, not when instances are created.
Metaclass for Validation
Use metaclasses to enforce rules at class definition time. Validates that required methods are implemented.
__init_subclass__ - Simpler Alternative
__init_subclass__ is simpler than metaclasses for many use cases. Runs when subclass is created. Use this instead of metaclasses when possible.