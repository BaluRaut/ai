{
  "en": {
    "topics": [
      {
        "id": "1",
        "title": "Linear Algebra - Vectors & Matrices",
        "description": "Foundation of machine learning: vectors, matrices, and linear transformations",
        "estimatedTime": "90 minutes",
        "difficulty": "Beginner",
        "content": {
          "overview": "Linear algebra is the backbone of machine learning. Understanding vectors and matrices is crucial for working with data, neural networks, and optimization algorithms.\n\n**Why It Matters:**\n• Neural networks are matrix multiplications\n• Data is represented as vectors and matrices\n• Principal Component Analysis (PCA) uses eigenvalues\n• Image processing relies on matrix operations",
          "keyPoints": [
            "Vectors represent data points in n-dimensional space",
            "Matrices transform and manipulate data",
            "Dot product measures similarity between vectors",
            "Matrix multiplication combines transformations",
            "Eigenvalues reveal important data patterns",
            "Inverse matrices help solve linear systems"
          ],
          "realWorldUseCases": {
            "recommendation": {
              "title": "Netflix Recommendation System",
              "description": "User-movie matrix factorization to predict ratings",
              "input": "User preferences matrix (users × movies)",
              "output": "Predicted ratings for unwatched movies",
              "math": "Matrix factorization: R ≈ U × V^T",
              "impact": "Personalized recommendations for millions of users"
            },
            "imageCompression": {
              "title": "Image Compression (JPEG)",
              "description": "Singular Value Decomposition to reduce image size",
              "input": "1920×1080 image matrix (2M pixels)",
              "output": "Compressed image with 10% size",
              "math": "SVD: A = U × Σ × V^T, keep top k singular values",
              "impact": "Faster image loading, less storage"
            },
            "faceRecognition": {
              "title": "Face Recognition (Eigenfaces)",
              "description": "PCA to extract facial features from images",
              "input": "Face images as high-dimensional vectors",
              "output": "Low-dimensional feature vectors",
              "math": "Eigenvalue decomposition of covariance matrix",
              "impact": "Fast face matching in security systems"
            },
            "pageRank": {
              "title": "Google PageRank Algorithm",
              "description": "Eigenvector of web link matrix determines page importance",
              "input": "Web graph adjacency matrix",
              "output": "Importance score for each webpage",
              "math": "Find dominant eigenvector of transition matrix",
              "impact": "Ranks billions of webpages for search results"
            }
          },
          "mathematicalFoundations": [
            {
              "concept": "Vector Operations",
              "formula": "v⃗ · w⃗ = v₁w₁ + v₂w₂ + ... + vₙwₙ",
              "explanation": "Dot product: sum of element-wise multiplication",
              "application": "Cosine similarity for document comparison"
            },
            {
              "concept": "Matrix Multiplication",
              "formula": "(AB)ᵢⱼ = Σₖ AᵢₖBₖⱼ",
              "explanation": "Combine transformations by multiplying matrices",
              "application": "Neural network forward propagation"
            },
            {
              "concept": "Eigenvalues & Eigenvectors",
              "formula": "Av⃗ = λv⃗",
              "explanation": "Special vectors that only scale under transformation",
              "application": "PCA finds directions of maximum variance"
            },
            {
              "concept": "Matrix Inverse",
              "formula": "AA⁻¹ = I",
              "explanation": "Inverse matrix undoes the transformation",
              "application": "Solving linear regression: θ = (X^T X)⁻¹ X^T y"
            }
          ],
          "codeExamples": [
            {
              "title": "Vector Operations - Cosine Similarity",
              "language": "python",
              "explanation": "Calculate similarity between two documents using vectors",
              "code": "import numpy as np\n\n# Document vectors (word frequencies)\ndoc1 = np.array([2, 3, 1, 0, 5])  # \"AI is amazing\"\ndoc2 = np.array([1, 2, 1, 1, 4])  # \"ML is great\"\n\n# Cosine similarity: cos(θ) = (v·w) / (|v||w|)\ndot_product = np.dot(doc1, doc2)\nmagnitude1 = np.linalg.norm(doc1)\nmagnitude2 = np.linalg.norm(doc2)\n\nsimilarity = dot_product / (magnitude1 * magnitude2)\nprint(f\"Document Similarity: {similarity:.3f}\")\n# Output: 0.982 (very similar)\n\n# Real-world: Google Search uses this to rank pages",
              "realWorldExample": "Search engines use cosine similarity to find relevant documents"
            },
            {
              "title": "Matrix Multiplication - Image Transformation",
              "language": "python",
              "explanation": "Rotate an image using matrix multiplication",
              "code": "import numpy as np\n\n# 2x2 image patch\nimage = np.array([[100, 200],\n                  [150, 250]])\n\n# Rotation matrix (90° clockwise)\ntheta = -np.pi/2\nrotation_matrix = np.array([\n    [np.cos(theta), -np.sin(theta)],\n    [np.sin(theta), np.cos(theta)]\n])\n\n# Apply transformation (simplified)\n# In practice, apply to pixel coordinates\nrotated = rotation_matrix @ image  # @ is matrix multiplication\nprint(rotated)\n\n# Real-world: Data augmentation in image training",
              "realWorldExample": "CNNs use matrix ops for image augmentation"
            },
            {
              "title": "Eigenvalues - Principal Component Analysis",
              "language": "python",
              "explanation": "Reduce dimensions while preserving variance",
              "code": "import numpy as np\nfrom sklearn.decomposition import PCA\n\n# High-dimensional data (100 samples, 50 features)\nX = np.random.randn(100, 50)\n\n# PCA: find top 2 principal components\npca = PCA(n_components=2)\nX_reduced = pca.fit_transform(X)\n\nprint(f\"Original shape: {X.shape}\")\nprint(f\"Reduced shape: {X_reduced.shape}\")\nprint(f\"Variance explained: {pca.explained_variance_ratio_}\")\n\n# Mathematics behind PCA:\n# 1. Center data: X_centered = X - mean(X)\n# 2. Covariance matrix: C = X^T X / n\n# 3. Eigendecomposition: C v = λ v\n# 4. Project onto top k eigenvectors\n\n# Real-world: Visualize high-dim data, remove noise",
              "realWorldExample": "Used in face recognition, data visualization, feature extraction"
            }
          ],
          "practicalAssignments": [
            {
              "title": "Build a Mini Recommendation System",
              "difficulty": "Medium",
              "estimatedTime": "45 minutes",
              "description": "Create movie recommendations using matrix factorization",
              "tasks": [
                "Create user-movie rating matrix (5 users × 8 movies)",
                "Implement collaborative filtering using SVD",
                "Predict ratings for unwatched movies",
                "Recommend top 3 movies per user",
                "Calculate prediction accuracy (RMSE)"
              ],
              "starterCode": "import numpy as np\n\n# User-movie ratings (0 = not watched)\nratings = np.array([\n    [5, 3, 0, 1, 4, 0, 0, 2],  # User 1\n    [4, 0, 0, 1, 0, 3, 0, 1],  # User 2\n    [1, 1, 0, 5, 0, 0, 4, 0],  # User 3\n    [0, 0, 4, 0, 0, 5, 3, 0],  # User 4\n    [0, 3, 5, 0, 1, 0, 0, 4],  # User 5\n])\n\n# TODO: Implement matrix factorization\n# TODO: Predict missing ratings\n# TODO: Generate recommendations",
              "expectedOutput": "User 1 recommendations: [Movie 3, Movie 6, Movie 7]"
            },
            {
              "title": "Image Compression with SVD",
              "difficulty": "Medium",
              "estimatedTime": "30 minutes",
              "description": "Compress images using Singular Value Decomposition",
              "tasks": [
                "Load a grayscale image as a matrix",
                "Apply SVD: A = U × Σ × V^T",
                "Keep top k singular values (k=10, 50, 100)",
                "Reconstruct image from compressed representation",
                "Compare file sizes and visual quality"
              ],
              "starterCode": "import numpy as np\nfrom PIL import Image\n\n# Load image\nimg = Image.open('photo.jpg').convert('L')\nimg_matrix = np.array(img)\n\n# TODO: Apply SVD\n# TODO: Reconstruct with different k values\n# TODO: Calculate compression ratio",
              "expectedOutput": "k=50: 90% compression, 95% quality retained"
            }
          ],
          "interactiveExercises": [
            {
              "question": "Calculate the dot product of v⃗ = [2, 3, 1] and w⃗ = [1, 4, 2]",
              "type": "calculation",
              "hint": "v⃗ · w⃗ = (2×1) + (3×4) + (1×2)",
              "answer": "16",
              "explanation": "2×1 + 3×4 + 1×2 = 2 + 12 + 2 = 16"
            },
            {
              "question": "What is the rank of a 100×50 matrix with full column rank?",
              "type": "multiple-choice",
              "options": [
                "100",
                "50",
                "150",
                "5000"
              ],
              "answer": "50",
              "explanation": "Rank = min(rows, cols) with full column rank = 50"
            }
          ],
          "quiz": [
            {
              "question": "In neural networks, what does matrix multiplication represent?",
              "options": [
                "Weighted sum of inputs",
                "Element-wise product",
                "Activation function",
                "Loss calculation"
              ],
              "correctAnswer": 0,
              "explanation": "Matrix multiplication computes weighted sums: y = Wx + b"
            },
            {
              "question": "What does PCA use to find principal components?",
              "options": [
                "Matrix inversion",
                "Eigenvalue decomposition",
                "Gradient descent",
                "Cross product"
              ],
              "correctAnswer": 1,
              "explanation": "PCA finds eigenvectors of covariance matrix (directions of max variance)"
            },
            {
              "question": "Cosine similarity ranges from:",
              "options": [
                "0 to 1",
                "-1 to 1",
                "0 to ∞",
                "-∞ to ∞"
              ],
              "correctAnswer": 1,
              "explanation": "Cosine similarity = cos(angle) ranges from -1 (opposite) to 1 (identical)"
            }
          ]
        }
      },
      {
        "id": "2",
        "title": "Calculus - Derivatives & Gradients",
        "description": "Understanding how neural networks learn through derivatives and backpropagation",
        "estimatedTime": "75 minutes",
        "difficulty": "Intermediate",
        "content": {
          "overview": "Calculus is the mathematics of change. In machine learning, we use derivatives to optimize models by finding how to adjust parameters to minimize error.\n\n**Why It Matters:**\n• Gradient descent uses derivatives to minimize loss\n• Backpropagation computes gradients through chain rule\n• Optimization algorithms rely on calculus\n• Understanding learning rates requires derivatives",
          "keyPoints": [
            "Derivative measures rate of change",
            "Gradient points in direction of steepest increase",
            "Chain rule enables backpropagation",
            "Partial derivatives handle multi-variable functions",
            "Second derivatives show curvature (Hessian)",
            "Taylor series approximate complex functions"
          ],
          "realWorldUseCases": {
            "neuralNetworkTraining": {
              "title": "Training Deep Neural Networks",
              "description": "Backpropagation uses chain rule to compute gradients",
              "input": "Network weights, training data batch",
              "output": "Updated weights via gradient descent",
              "math": "∂Loss/∂w = ∂Loss/∂output × ∂output/∂w",
              "impact": "Trains models with billions of parameters (GPT, BERT)"
            },
            "selfDrivingCars": {
              "title": "Self-Driving Car Optimization",
              "description": "Minimize trajectory cost function using calculus",
              "input": "Current position, destination, obstacles",
              "output": "Optimal steering/acceleration commands",
              "math": "Minimize: C(x) = safety_cost + efficiency_cost + comfort_cost",
              "impact": "Safe, smooth autonomous driving"
            },
            "stockTrading": {
              "title": "Algorithmic Trading",
              "description": "Optimize portfolio using derivatives of risk/return",
              "input": "Stock prices, risk tolerance",
              "output": "Optimal asset allocation",
              "math": "Maximize: E[return] - λ × Var[return]",
              "impact": "Billions in automated trading daily"
            },
            "imageUpscaling": {
              "title": "AI Image Super-Resolution",
              "description": "Generate high-res images by minimizing perceptual loss",
              "input": "Low-resolution image",
              "output": "High-resolution image",
              "math": "Minimize perceptual loss using gradient descent",
              "impact": "Enhance old photos, improve video quality"
            }
          },
          "mathematicalFoundations": [
            {
              "concept": "Derivative",
              "formula": "f'(x) = lim(h→0) [f(x+h) - f(x)] / h",
              "explanation": "Instantaneous rate of change",
              "application": "How much does loss change with weight adjustment?"
            },
            {
              "concept": "Chain Rule",
              "formula": "∂f/∂x = (∂f/∂u) × (∂u/∂x)",
              "explanation": "Derivative of composite functions",
              "application": "Backpropagation through neural network layers"
            },
            {
              "concept": "Gradient",
              "formula": "∇f = [∂f/∂x₁, ∂f/∂x₂, ..., ∂f/∂xₙ]",
              "explanation": "Vector of all partial derivatives",
              "application": "Direction to move in parameter space"
            },
            {
              "concept": "Taylor Series",
              "formula": "f(x) ≈ f(a) + f'(a)(x-a) + f''(a)(x-a)²/2! + ...",
              "explanation": "Approximate functions with polynomials",
              "application": "Second-order optimization methods (Newton's method)"
            }
          ],
          "codeExamples": [
            {
              "title": "Gradient Descent - Linear Regression",
              "language": "python",
              "explanation": "Use derivatives to find best-fit line",
              "code": "import numpy as np\nimport matplotlib.pyplot as plt\n\n# Generate data: y = 3x + 2 + noise\nnp.random.seed(42)\nX = np.linspace(0, 10, 100)\ny = 3 * X + 2 + np.random.randn(100) * 2\n\n# Initialize parameters\nw = 0.0  # slope\nb = 0.0  # intercept\nlearning_rate = 0.01\nepochs = 100\n\n# Gradient descent\nfor epoch in range(epochs):\n    # Predictions\n    y_pred = w * X + b\n    \n    # Loss: Mean Squared Error\n    loss = np.mean((y_pred - y) ** 2)\n    \n    # Gradients (derivatives of loss)\n    dw = 2 * np.mean((y_pred - y) * X)\n    db = 2 * np.mean(y_pred - y)\n    \n    # Update parameters\n    w -= learning_rate * dw\n    b -= learning_rate * db\n    \n    if epoch % 20 == 0:\n        print(f\"Epoch {epoch}: Loss={loss:.3f}, w={w:.3f}, b={b:.3f}\")\n\nprint(f\"\\nFinal: w={w:.3f} (true=3), b={b:.3f} (true=2)\")",
              "realWorldExample": "Predicting house prices, stock trends, sales forecasts"
            },
            {
              "title": "Backpropagation - Simple Neural Network",
              "language": "python",
              "explanation": "Chain rule to compute gradients through layers",
              "code": "import numpy as np\n\ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n\ndef sigmoid_derivative(x):\n    return x * (1 - x)\n\n# Input and output\nX = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\ny = np.array([[0], [1], [1], [0]])  # XOR problem\n\n# Initialize weights\nnp.random.seed(1)\nw1 = np.random.randn(2, 2)  # Input to hidden\nw2 = np.random.randn(2, 1)  # Hidden to output\n\nlearning_rate = 1.0\n\n# Training\nfor epoch in range(10000):\n    # Forward pass\n    layer1 = sigmoid(X @ w1)\n    output = sigmoid(layer1 @ w2)\n    \n    # Backward pass (chain rule!)\n    error = y - output\n    d_output = error * sigmoid_derivative(output)\n    \n    # Chain rule: ∂L/∂w2 = ∂L/∂output × ∂output/∂w2\n    error_layer1 = d_output @ w2.T\n    d_layer1 = error_layer1 * sigmoid_derivative(layer1)\n    \n    # Update weights\n    w2 += layer1.T @ d_output * learning_rate\n    w1 += X.T @ d_layer1 * learning_rate\n\nprint(\"Predictions (should be near [0, 1, 1, 0]):\")\nprint(output.round(2))",
              "realWorldExample": "Training deep networks for image recognition, language models"
            }
          ],
          "practicalAssignments": [
            {
              "title": "Implement Mini-Batch Gradient Descent",
              "difficulty": "Medium",
              "estimatedTime": "40 minutes",
              "description": "Train logistic regression with mini-batch updates",
              "tasks": [
                "Generate binary classification dataset",
                "Implement sigmoid activation",
                "Compute cross-entropy loss",
                "Calculate gradients for mini-batches",
                "Update weights and track convergence"
              ],
              "starterCode": "import numpy as np\n\n# TODO: Generate dataset (sklearn.make_classification)\n# TODO: Implement sigmoid(z) = 1 / (1 + e^-z)\n# TODO: Loss = -mean(y*log(pred) + (1-y)*log(1-pred))\n# TODO: Gradient = X^T (pred - y) / batch_size\n# TODO: Train with batch_size=32, learning_rate=0.01",
              "expectedOutput": "Accuracy: 95%+, Loss converges smoothly"
            }
          ],
          "quiz": [
            {
              "question": "What does the gradient vector point towards?",
              "options": [
                "Direction of steepest decrease",
                "Direction of steepest increase",
                "Minimum of function",
                "Random direction"
              ],
              "correctAnswer": 1,
              "explanation": "Gradient points uphill (increase). We move in -gradient direction to minimize."
            },
            {
              "question": "In backpropagation, what mathematical rule enables computing gradients?",
              "options": [
                "Product rule",
                "Chain rule",
                "Quotient rule",
                "Power rule"
              ],
              "correctAnswer": 1,
              "explanation": "Chain rule: ∂f/∂x = (∂f/∂u)(∂u/∂x) propagates gradients backward through layers"
            }
          ]
        }
      },
      {
        "id": "3",
        "title": "Probability Theory - Foundations of ML",
        "description": "Understand probability distributions, Bayes theorem, and uncertainty quantification",
        "estimatedTime": "80 minutes",
        "difficulty": "Intermediate",
        "content": {
          "overview": "Probability is fundamental to machine learning. Classification outputs probabilities, generative models sample from distributions, and Bayesian methods quantify uncertainty.\n\n**Why It Matters:**\n• Softmax converts scores to probabilities\n• Naive Bayes classifier uses conditional probability\n• Generative models (GANs, VAEs) learn distributions\n• Uncertainty estimation in predictions",
          "keyPoints": [
            "Probability measures likelihood of events (0 to 1)",
            "Conditional probability: P(A|B) = P(A∩B) / P(B)",
            "Bayes theorem updates beliefs with evidence",
            "Distributions model random variables",
            "Expected value is weighted average",
            "Independence simplifies calculations"
          ],
          "realWorldUseCases": {
            "spamFilter": {
              "title": "Email Spam Detection (Naive Bayes)",
              "description": "Calculate probability email is spam given words",
              "input": "Email text: \"FREE winner! Click now!\"",
              "output": "P(Spam|words) = 0.95 → Spam",
              "math": "P(Spam|words) = P(words|Spam) × P(Spam) / P(words)",
              "impact": "Filters billions of spam emails daily"
            },
            "medicalDiagnosis": {
              "title": "Disease Diagnosis with Bayes Theorem",
              "description": "Update disease probability after positive test",
              "input": "Positive test result, disease prevalence 1%",
              "output": "True probability of having disease",
              "math": "P(Disease|+) = P(+|Disease) × P(Disease) / P(+)",
              "impact": "Accurate medical decisions despite false positives"
            },
            "weatherForecasting": {
              "title": "Weather Prediction Probabilities",
              "description": "Ensemble models output probability distributions",
              "input": "Temperature, pressure, humidity data",
              "output": "P(Rain tomorrow) = 0.73",
              "math": "Combine multiple model predictions with weights",
              "impact": "Reliable forecasts for agriculture, aviation"
            },
            "recommendationSystems": {
              "title": "Netflix Content Recommendations",
              "description": "Probability user will like item based on history",
              "input": "User watch history, item features",
              "output": "P(User likes Movie | features) = 0.88",
              "math": "Collaborative filtering with probabilistic matrix factorization",
              "impact": "Personalized content for 200M+ subscribers"
            }
          },
          "mathematicalFoundations": [
            {
              "concept": "Basic Probability",
              "formula": "P(A) = favorable outcomes / total outcomes",
              "explanation": "Ratio of desired events to all possible events",
              "application": "Coin flip: P(Heads) = 1/2, Dice: P(6) = 1/6"
            },
            {
              "concept": "Conditional Probability",
              "formula": "P(A|B) = P(A ∩ B) / P(B)",
              "explanation": "Probability of A given B has occurred",
              "application": "P(Spam | contains \"free\") in email filtering"
            },
            {
              "concept": "Bayes Theorem",
              "formula": "P(A|B) = P(B|A) × P(A) / P(B)",
              "explanation": "Update prior belief P(A) with evidence B",
              "application": "Medical diagnosis, spam classification, A/B testing"
            },
            {
              "concept": "Expected Value",
              "formula": "E[X] = Σ x × P(X=x)",
              "explanation": "Weighted average of all possible values",
              "application": "Expected return in finance, average prediction error"
            },
            {
              "concept": "Independence",
              "formula": "P(A ∩ B) = P(A) × P(B)",
              "explanation": "Events don't affect each other",
              "application": "Naive Bayes assumes feature independence"
            },
            {
              "concept": "Law of Total Probability",
              "formula": "P(A) = Σ P(A|Bᵢ) × P(Bᵢ)",
              "explanation": "Sum over all possible conditions",
              "application": "Marginalizing out variables in probabilistic models"
            }
          ],
          "distributions": {
            "discrete": [
              {
                "name": "Bernoulli",
                "formula": "P(X=1) = p, P(X=0) = 1-p",
                "description": "Single trial with two outcomes (success/failure)",
                "example": "Coin flip, binary classification",
                "parameters": "p (probability of success)"
              },
              {
                "name": "Binomial",
                "formula": "P(X=k) = C(n,k) × p^k × (1-p)^(n-k)",
                "description": "Number of successes in n independent trials",
                "example": "Number of heads in 10 coin flips",
                "parameters": "n (trials), p (success probability)"
              },
              {
                "name": "Poisson",
                "formula": "P(X=k) = (λ^k × e^(-λ)) / k!",
                "description": "Number of events in fixed interval",
                "example": "Website visits per hour, customer arrivals",
                "parameters": "λ (average rate)"
              }
            ],
            "continuous": [
              {
                "name": "Normal (Gaussian)",
                "formula": "f(x) = (1/√(2πσ²)) × e^(-(x-μ)²/(2σ²))",
                "description": "Bell curve - most common distribution",
                "example": "Heights, IQ scores, measurement errors",
                "parameters": "μ (mean), σ (std deviation)",
                "properties": "68-95-99.7 rule: 68% within 1σ, 95% within 2σ, 99.7% within 3σ"
              },
              {
                "name": "Uniform",
                "formula": "f(x) = 1/(b-a) for x ∈ [a,b]",
                "description": "All outcomes equally likely",
                "example": "Random number generation, dice roll",
                "parameters": "a (min), b (max)"
              },
              {
                "name": "Exponential",
                "formula": "f(x) = λe^(-λx) for x ≥ 0",
                "description": "Time until event occurs",
                "example": "Time between customer arrivals, radioactive decay",
                "parameters": "λ (rate)"
              }
            ]
          },
          "codeExamples": [
            {
              "title": "Bayes Theorem - Spam Filter",
              "language": "python",
              "explanation": "Use Bayes to classify emails as spam or not",
              "code": "import numpy as np\n\n# Spam filter example\nprint(\"=== Email Spam Classification ===\\n\")\n\n# Prior probabilities\nP_spam = 0.3  # 30% of emails are spam\nP_ham = 0.7   # 70% are legitimate\n\n# Likelihood: P(word | class)\n# Word \"free\" appears in:\nP_free_given_spam = 0.8  # 80% of spam\nP_free_given_ham = 0.1   # 10% of legitimate\n\n# Email contains \"free\" - what's P(Spam | \"free\")?\n\n# Law of total probability: P(\"free\")\nP_free = P_free_given_spam * P_spam + P_free_given_ham * P_ham\nprint(f'P(\"free\") = {P_free:.3f}')\n\n# Bayes Theorem\nP_spam_given_free = (P_free_given_spam * P_spam) / P_free\nprint(f'P(Spam | \"free\") = {P_spam_given_free:.3f}')\nprint(f'P(Ham | \"free\") = {1 - P_spam_given_free:.3f}')\n\nprint(f'\\n→ Email with \"free\" is {P_spam_given_free:.1%} likely spam')",
              "realWorldExample": "Gmail filters 100B+ spam emails yearly"
            },
            {
              "title": "Probability Distributions",
              "language": "python",
              "explanation": "Work with common probability distributions",
              "code": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\n# 1. Binomial: Coin flips\nn, p = 10, 0.5  # 10 flips, fair coin\nbinomial = stats.binom(n, p)\nprint(\"Binomial(n=10, p=0.5):\")\nprint(f\"  P(X=5) = {binomial.pmf(5):.4f}\")\nprint(f\"  P(X≤7) = {binomial.cdf(7):.4f}\")\nprint(f\"  Mean = {binomial.mean():.1f}\")\nprint(f\"  Std = {binomial.std():.2f}\")\n\n# 2. Normal: IQ scores\nmu, sigma = 100, 15  # IQ distribution\nnormal = stats.norm(mu, sigma)\nprint(f\"\\nNormal(μ={mu}, σ={sigma}):\")\nprint(f\"  P(X < 115) = {normal.cdf(115):.4f}\")\nprint(f\"  P(85 < X < 115) = {normal.cdf(115) - normal.cdf(85):.4f}\")\nprint(f\"  95th percentile = {normal.ppf(0.95):.1f}\")\n\n# 3. Poisson: Website visits\nlambda_rate = 5  # 5 visits per hour\npoisson = stats.poisson(lambda_rate)\nprint(f\"\\nPoisson(λ={lambda_rate}):\")\nprint(f\"  P(X=5) = {poisson.pmf(5):.4f}\")\nprint(f\"  P(X≥3) = {1 - poisson.cdf(2):.4f}\")",
              "realWorldExample": "A/B testing, quality control, risk assessment"
            },
            {
              "title": "Naive Bayes Classifier from Scratch",
              "language": "python",
              "explanation": "Build spam classifier using probability",
              "code": "import numpy as np\n\nclass NaiveBayes:\n    def fit(self, X, y):\n        n_samples, n_features = X.shape\n        self.classes = np.unique(y)\n        \n        # Prior: P(class)\n        self.priors = {}\n        # Likelihood: P(feature | class)\n        self.mean = {}\n        self.var = {}\n        \n        for c in self.classes:\n            X_c = X[y == c]\n            self.priors[c] = len(X_c) / n_samples\n            self.mean[c] = X_c.mean(axis=0)\n            self.var[c] = X_c.var(axis=0)\n    \n    def _pdf(self, x, mean, var):\n        # Gaussian probability density\n        return np.exp(-((x - mean)**2) / (2*var)) / np.sqrt(2*np.pi*var)\n    \n    def predict(self, X):\n        predictions = []\n        for x in X:\n            posteriors = {}\n            for c in self.classes:\n                # Prior\n                prior = np.log(self.priors[c])\n                # Likelihood (assuming independence)\n                likelihood = np.sum(np.log(self._pdf(x, self.mean[c], self.var[c])))\n                # Posterior ∝ Prior × Likelihood\n                posteriors[c] = prior + likelihood\n            predictions.append(max(posteriors, key=posteriors.get))\n        return np.array(predictions)\n\n# Test on iris dataset\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\n\niris = load_iris()\nX_train, X_test, y_train, y_test = train_test_split(\n    iris.data, iris.target, test_size=0.3, random_state=42\n)\n\nnb = NaiveBayes()\nnb.fit(X_train, y_train)\npredictions = nb.predict(X_test)\naccuracy = np.mean(predictions == y_test)\nprint(f\"Accuracy: {accuracy:.1%}\")",
              "realWorldExample": "Text classification, sentiment analysis, medical diagnosis"
            }
          ],
          "practicalAssignments": [
            {
              "title": "Build Medical Diagnosis System",
              "difficulty": "Medium",
              "estimatedTime": "50 minutes",
              "description": "Use Bayes theorem to calculate disease probability",
              "tasks": [
                "Implement Bayes theorem function",
                "Calculate P(Disease|+Test) with given prevalence and test accuracy",
                "Handle multiple test results (update probability iteratively)",
                "Visualize how posterior changes with evidence",
                "Test with different prior probabilities"
              ],
              "starterCode": "import numpy as np\n\ndef bayes_update(prior, likelihood_true, likelihood_false, evidence=True):\n    \"\"\"\n    Update probability using Bayes theorem.\n    \n    Args:\n        prior: P(Disease)\n        likelihood_true: P(+Test | Disease)\n        likelihood_false: P(+Test | No Disease)\n        evidence: True if test positive\n    \n    Returns:\n        Posterior probability P(Disease | Test)\n    \"\"\"\n    # TODO: Implement Bayes theorem\n    # P(Disease | +) = P(+ | Disease) * P(Disease) / P(+)\n    # where P(+) = P(+ | Disease)*P(Disease) + P(+ | No Disease)*P(No Disease)\n    pass\n\n# Example: Rare disease (1% prevalence), test 99% accurate\n# TODO: Calculate probability after positive test\n# TODO: What if test negative?\n# TODO: What about two positive tests in a row?",
              "expectedOutput": "P(Disease|+Test) ≈ 0.50 (not 0.99!), demonstrates base rate fallacy"
            },
            {
              "title": "Monte Carlo Simulation",
              "difficulty": "Easy",
              "estimatedTime": "30 minutes",
              "description": "Estimate probabilities through random sampling",
              "tasks": [
                "Simulate 10,000 dice rolls",
                "Estimate probability of sum=7 with two dice",
                "Calculate empirical vs theoretical probability",
                "Visualize distribution of outcomes",
                "Compute confidence interval for estimate"
              ],
              "starterCode": "import numpy as np\n\n# TODO: Simulate rolling two dice 10,000 times\n# TODO: Count how often sum equals 7\n# TODO: Compare to theoretical P(sum=7) = 6/36\n# Theoretical: (1,6), (2,5), (3,4), (4,3), (5,2), (6,1)",
              "expectedOutput": "Empirical probability ≈ 0.167, close to theoretical 6/36 ≈ 0.167"
            }
          ],
          "videoResources": [
            {
              "title": "3Blue1Brown - Bayes Theorem Visualized",
              "url": "https://www.youtube.com/watch?v=HZGCoVF3YvM",
              "duration": "15 min",
              "description": "Beautiful visual explanation of Bayes theorem"
            },
            {
              "title": "StatQuest - Probability Distributions",
              "url": "https://www.youtube.com/watch?v=rzFX5NWojp0",
              "duration": "10 min",
              "description": "Clear introduction to common distributions"
            },
            {
              "title": "Khan Academy - Conditional Probability",
              "url": "https://www.khanacademy.org/math/statistics-probability/probability-library",
              "duration": "30 min",
              "description": "Complete probability fundamentals course"
            }
          ],
          "cheatSheet": {
            "formulas": [
              "P(A|B) = P(A∩B) / P(B) - Conditional probability",
              "P(A|B) = P(B|A)P(A) / P(B) - Bayes theorem",
              "P(A∪B) = P(A) + P(B) - P(A∩B) - Union",
              "P(A∩B) = P(A)P(B) if independent",
              "E[X] = Σ x·P(x) - Expected value",
              "Var(X) = E[X²] - E[X]² - Variance"
            ],
            "distributions": [
              "Bernoulli(p): Binary outcome",
              "Binomial(n,p): n trials, count successes",
              "Poisson(λ): Events in interval",
              "Normal(μ,σ): Bell curve, 68-95-99.7 rule",
              "Uniform(a,b): Equal probability",
              "Exponential(λ): Time until event"
            ]
          },
          "commonPitfalls": [
            {
              "mistake": "Confusing P(A|B) with P(B|A)",
              "example": "P(Positive Test | Disease) ≠ P(Disease | Positive Test)",
              "fix": "Always use Bayes theorem to flip conditional probabilities"
            },
            {
              "mistake": "Assuming independence when features are correlated",
              "example": "Naive Bayes assumes all features independent",
              "fix": "Check correlation matrix, consider dependencies"
            },
            {
              "mistake": "Ignoring base rates (prior probabilities)",
              "example": "Rare disease: even accurate test → low P(Disease|+)",
              "fix": "Always incorporate P(Disease) in calculations"
            },
            {
              "mistake": "Adding probabilities incorrectly",
              "example": "P(A∪B) = P(A) + P(B) only if mutually exclusive",
              "fix": "Use P(A∪B) = P(A) + P(B) - P(A∩B)"
            }
          ],
          "tipsAndTricks": [
            "Draw probability trees for complex problems",
            "Use simulation (Monte Carlo) when formulas are hard",
            "Check if P(total) = 1 (probabilities must sum to 1)",
            "Log probabilities prevent numerical underflow",
            "Normalize at the end: P(A|B) ∝ P(B|A)P(A)",
            "Memorize 68-95-99.7 rule for normal distribution"
          ],
          "interactiveExercises": [
            {
              "type": "calculation",
              "question": "A bag has 3 red, 2 blue balls. Pick 2 without replacement. P(both red)?",
              "hint": "P(R₁ ∩ R₂) = P(R₁) × P(R₂|R₁)",
              "solution": "(3/5) × (2/4) = 6/20 = 0.3",
              "steps": [
                "P(R₁) = 3/5",
                "After taking 1 red, 2 red out of 4 remain",
                "P(R₂|R₁) = 2/4",
                "Multiply: (3/5)(2/4) = 0.3"
              ]
            },
            {
              "type": "calculation",
              "question": "Disease affects 2% of population. Test: 95% sensitive, 90% specific. You test positive. P(Disease)?",
              "hint": "Use Bayes: P(D|+) = P(+|D)P(D) / P(+)",
              "solution": "P(D|+) ≈ 0.161 or 16.1%",
              "steps": [
                "P(D) = 0.02, P(no D) = 0.98",
                "P(+|D) = 0.95, P(+|no D) = 0.10",
                "P(+) = 0.95×0.02 + 0.10×0.98 = 0.117",
                "P(D|+) = 0.95×0.02 / 0.117 ≈ 0.162"
              ]
            }
          ],
          "quiz": [
            {
              "question": "What is P(A|B) if A and B are independent?",
              "options": [
                "P(A)",
                "P(B)",
                "P(A) × P(B)",
                "0"
              ],
              "correctAnswer": 0,
              "explanation": "If independent, knowing B doesn't change probability of A: P(A|B) = P(A)"
            },
            {
              "question": "Bayes theorem is used to calculate:",
              "options": [
                "P(A) from P(B)",
                "P(A|B) from P(B|A)",
                "P(A∩B) from P(A∪B)",
                "E[X] from Var(X)"
              ],
              "correctAnswer": 1,
              "explanation": "Bayes theorem: P(A|B) = P(B|A)P(A)/P(B) - flips conditionals"
            },
            {
              "question": "Which distribution models time between events?",
              "options": [
                "Binomial",
                "Poisson",
                "Exponential",
                "Normal"
              ],
              "correctAnswer": 2,
              "explanation": "Exponential distribution models continuous time until next event"
            },
            {
              "question": "In a normal distribution, what % of data is within 2 standard deviations?",
              "options": [
                "68%",
                "95%",
                "99.7%",
                "90%"
              ],
              "correctAnswer": 1,
              "explanation": "68-95-99.7 rule: 95% within 2σ of mean"
            }
          ]
        }
      },
      {
        "id": "4",
        "title": "Statistics - Data Analysis & Hypothesis Testing",
        "description": "Master statistical inference, confidence intervals, and A/B testing",
        "estimatedTime": "85 minutes",
        "difficulty": "Intermediate",
        "content": {
          "overview": "Statistics transforms raw data into insights. In ML, we use statistics for feature engineering, model evaluation, and making data-driven decisions.\n\n**Why It Matters:**\n• Evaluate model performance with statistical tests\n• A/B testing determines if changes are significant\n• Confidence intervals quantify uncertainty\n• Feature selection uses correlation analysis",
          "keyPoints": [
            "Mean, median, mode describe central tendency",
            "Variance and standard deviation measure spread",
            "Correlation shows relationship between variables",
            "Hypothesis testing determines statistical significance",
            "p-value < 0.05 typically means significant result",
            "Confidence intervals provide range of plausible values"
          ],
          "realWorldUseCases": {
            "abTesting": {
              "title": "A/B Testing for Website Optimization",
              "description": "Determine if new design increases conversion rate",
              "input": "Version A: 1000 visits, 50 conversions | Version B: 1000 visits, 65 conversions",
              "output": "p-value = 0.03 → Significant improvement",
              "math": "Two-sample proportion test: z = (p₁ - p₂) / SE",
              "impact": "Billion-dollar decisions at Google, Amazon, Meta"
            },
            "qualityControl": {
              "title": "Manufacturing Quality Control",
              "description": "Detect if production process has shifted",
              "input": "Sample mean = 100.5, historical mean = 100",
              "output": "Within control limits → Process OK",
              "math": "Control chart: μ ± 3σ boundaries",
              "impact": "Prevent defective products, reduce waste"
            },
            "clinicalTrials": {
              "title": "Drug Efficacy Testing",
              "description": "Prove new drug better than placebo",
              "input": "Treatment group vs control group outcomes",
              "output": "p < 0.001 → Drug is effective",
              "math": "t-test: t = (x̄₁ - x̄₂) / SE",
              "impact": "FDA approval requires statistical significance"
            },
            "featureSelection": {
              "title": "ML Feature Importance Analysis",
              "description": "Identify which features predict target",
              "input": "100 features, 10,000 samples",
              "output": "Top 10 features with p < 0.01",
              "math": "Correlation coefficient: r = cov(X,Y) / (σₓσᵧ)",
              "impact": "Reduce model complexity, improve interpretability"
            }
          },
          "mathematicalFoundations": [
            {
              "concept": "Mean (Average)",
              "formula": "μ = (1/n) Σ xᵢ",
              "explanation": "Sum all values and divide by count",
              "application": "Average prediction error, mean response time"
            },
            {
              "concept": "Variance",
              "formula": "σ² = (1/n) Σ (xᵢ - μ)²",
              "explanation": "Average squared deviation from mean",
              "application": "Measure prediction variability, data spread"
            },
            {
              "concept": "Standard Deviation",
              "formula": "σ = √Variance",
              "explanation": "Square root of variance (same units as data)",
              "application": "Typical distance from mean, outlier detection"
            },
            {
              "concept": "Correlation",
              "formula": "r = cov(X,Y) / (σₓ × σᵧ)",
              "explanation": "Measures linear relationship (-1 to +1)",
              "application": "Feature correlation, multicollinearity detection"
            },
            {
              "concept": "t-statistic",
              "formula": "t = (x̄ - μ₀) / (s/√n)",
              "explanation": "How many standard errors is sample mean from hypothesized value",
              "application": "Compare two groups, hypothesis testing"
            },
            {
              "concept": "Confidence Interval",
              "formula": "CI = x̄ ± t* × (s/√n)",
              "explanation": "Range containing true parameter with X% confidence",
              "application": "95% CI: if repeat experiment 100 times, 95 CIs contain true mean"
            },
            {
              "concept": "p-value",
              "formula": "P(observe data | H₀ is true)",
              "explanation": "Probability of seeing result if null hypothesis true",
              "application": "p < 0.05: reject null hypothesis (5% significance level)"
            }
          ],
          "statisticalTests": [
            {
              "name": "t-test",
              "purpose": "Compare means of two groups",
              "assumptions": "Normal distribution, equal variances",
              "example": "Does caffeine improve test scores?",
              "hypotheses": "H₀: μ₁ = μ₂ vs H₁: μ₁ ≠ μ₂"
            },
            {
              "name": "Chi-Square Test",
              "purpose": "Test independence of categorical variables",
              "assumptions": "Expected frequency ≥ 5 in each cell",
              "example": "Is gender related to product preference?",
              "hypotheses": "H₀: Variables independent vs H₁: Associated"
            },
            {
              "name": "ANOVA",
              "purpose": "Compare means of 3+ groups",
              "assumptions": "Normal, equal variances across groups",
              "example": "Do 3 teaching methods produce different scores?",
              "hypotheses": "H₀: μ₁ = μ₂ = μ₃ vs H₁: At least one differs"
            },
            {
              "name": "Correlation Test",
              "purpose": "Test if correlation is significant",
              "assumptions": "Linear relationship, bivariate normal",
              "example": "Is study time correlated with grades?",
              "hypotheses": "H₀: ρ = 0 vs H₁: ρ ≠ 0"
            }
          ],
          "codeExamples": [
            {
              "title": "Descriptive Statistics",
              "language": "python",
              "explanation": "Calculate central tendency and spread",
              "code": "import numpy as np\nfrom scipy import stats\n\n# Sample data: exam scores\nscores = np.array([85, 92, 78, 95, 88, 76, 91, 84, 89, 93])\n\nprint(\"=== Descriptive Statistics ===\\n\")\n\n# Central Tendency\nprint(f\"Mean: {np.mean(scores):.2f}\")\nprint(f\"Median: {np.median(scores):.2f}\")\nprint(f\"Mode: {stats.mode(scores, keepdims=True).mode[0]}\")\n\n# Spread\nprint(f\"\\nVariance: {np.var(scores, ddof=1):.2f}\")\nprint(f\"Std Dev: {np.std(scores, ddof=1):.2f}\")\nprint(f\"Range: {np.ptp(scores)}\")\n\n# Percentiles\nprint(f\"\\n25th percentile: {np.percentile(scores, 25):.1f}\")\nprint(f\"75th percentile: {np.percentile(scores, 75):.1f}\")\nprint(f\"IQR: {stats.iqr(scores):.1f}\")",
              "realWorldExample": "Analyze customer spending, response times, model accuracy"
            },
            {
              "title": "Hypothesis Testing - t-test",
              "language": "python",
              "explanation": "Compare two groups statistically",
              "code": "import numpy as np\nfrom scipy import stats\n\n# A/B test: old vs new website design\n# Metric: time on site (seconds)\nold_design = np.array([120, 135, 118, 142, 128, 131, 125, 138])\nnew_design = np.array([145, 152, 148, 160, 143, 155, 149, 158])\n\nprint(\"=== A/B Test: Two-Sample t-test ===\\n\")\n\n# Descriptive\nprint(f\"Old design: mean={old_design.mean():.1f}, std={old_design.std():.1f}\")\nprint(f\"New design: mean={new_design.mean():.1f}, std={new_design.std():.1f}\")\nprint(f\"Difference: {new_design.mean() - old_design.mean():.1f} seconds\")\n\n# t-test\nt_stat, p_value = stats.ttest_ind(new_design, old_design)\n\nprint(f\"\\nt-statistic: {t_stat:.4f}\")\nprint(f\"p-value: {p_value:.4f}\")\n\nalpha = 0.05\nif p_value < alpha:\n    print(f\"\\n✓ Result: SIGNIFICANT (p < {alpha})\")\n    print(\"  Reject null hypothesis: new design performs better\")\nelse:\n    print(f\"\\n✗ Result: NOT significant (p ≥ {alpha})\")\n    print(\"  Cannot conclude new design is better\")",
              "realWorldExample": "Google runs thousands of A/B tests yearly"
            },
            {
              "title": "Confidence Intervals",
              "language": "python",
              "explanation": "Quantify uncertainty in estimates",
              "code": "import numpy as np\nfrom scipy import stats\n\n# Customer satisfaction survey scores\nsurvey = np.array([7.2, 8.1, 6.9, 7.8, 8.5, 7.3, 8.0, 7.6, 8.2, 7.9])\n\nprint(\"=== 95% Confidence Interval ===\\n\")\n\nmean = np.mean(survey)\nstd_err = stats.sem(survey)  # Standard error\nconfidence = 0.95\n\n# t-distribution (unknown population std)\ndf = len(survey) - 1  # degrees of freedom\nt_crit = stats.t.ppf((1 + confidence) / 2, df)\n\nmargin_error = t_crit * std_err\nci_lower = mean - margin_error\nci_upper = mean + margin_error\n\nprint(f\"Sample mean: {mean:.2f}\")\nprint(f\"Standard error: {std_err:.3f}\")\nprint(f\"\\n95% CI: [{ci_lower:.2f}, {ci_upper:.2f}]\")\nprint(f\"\\nInterpretation: We are 95% confident the true\")\nprint(f\"population mean is between {ci_lower:.2f} and {ci_upper:.2f}\")",
              "realWorldExample": "Political polls, quality metrics, financial forecasting"
            },
            {
              "title": "Correlation Analysis",
              "language": "python",
              "explanation": "Measure relationships between variables",
              "code": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\n# Study hours vs exam score\nstudy_hours = np.array([2, 3, 5, 7, 8, 10, 12, 15, 18, 20])\nexam_score = np.array([55, 62, 70, 78, 82, 88, 91, 95, 97, 99])\n\nprint(\"=== Correlation Analysis ===\\n\")\n\n# Pearson correlation\nr, p_value = stats.pearsonr(study_hours, exam_score)\n\nprint(f\"Pearson correlation: r = {r:.4f}\")\nprint(f\"p-value: {p_value:.6f}\")\n\n# Interpret strength\nif abs(r) < 0.3:\n    strength = \"weak\"\nelif abs(r) < 0.7:\n    strength = \"moderate\"\nelse:\n    strength = \"strong\"\n\nprint(f\"\\nInterpretation: {strength} {'positive' if r > 0 else 'negative'} correlation\")\n\nif p_value < 0.05:\n    print(\"Correlation is statistically significant\")\nelse:\n    print(\"Correlation is NOT significant\")\n\n# Coefficient of determination\nr_squared = r ** 2\nprint(f\"\\nR² = {r_squared:.4f}\")\nprint(f\"{r_squared*100:.1f}% of variance in score explained by study hours\")",
              "realWorldExample": "Feature selection, multicollinearity detection, EDA"
            }
          ],
          "practicalAssignments": [
            {
              "title": "Build A/B Test Calculator",
              "difficulty": "Medium",
              "estimatedTime": "45 minutes",
              "description": "Create tool to analyze A/B test results with statistical rigor",
              "tasks": [
                "Input: visitors and conversions for A and B",
                "Calculate conversion rates and difference",
                "Perform two-proportion z-test",
                "Compute p-value and confidence interval",
                "Visualize results with error bars",
                "Determine sample size needed for 80% power"
              ],
              "starterCode": "import numpy as np\nfrom scipy import stats\n\ndef ab_test(visitors_a, conversions_a, visitors_b, conversions_b, alpha=0.05):\n    \"\"\"\n    Perform A/B test on conversion rates.\n    \n    Returns:\n        dict with conversion rates, p-value, CI, conclusion\n    \"\"\"\n    # TODO: Calculate conversion rates\n    # TODO: Pooled proportion for z-test\n    # TODO: Standard error\n    # TODO: z-statistic and p-value\n    # TODO: Confidence interval for difference\n    # TODO: Return structured results\n    pass\n\n# Example: Website redesign\n# A: 10000 visitors, 500 conversions (5.0%)\n# B: 10000 visitors, 580 conversions (5.8%)\n# Is B significantly better?",
              "expectedOutput": "p-value < 0.05 → Yes, B is significantly better at 95% confidence"
            },
            {
              "title": "Feature Correlation Analysis",
              "difficulty": "Easy",
              "estimatedTime": "35 minutes",
              "description": "Analyze correlations in dataset to identify important features",
              "tasks": [
                "Load dataset (e.g., iris, housing)",
                "Calculate correlation matrix",
                "Create heatmap visualization",
                "Identify highly correlated pairs (|r| > 0.7)",
                "Test significance of each correlation",
                "Report top 5 features correlated with target"
              ],
              "starterCode": "import numpy as np\nimport pandas as pd\nfrom scipy import stats\nimport seaborn as sns\n\n# TODO: Load dataset\n# TODO: Compute correlation matrix\n# TODO: Create heatmap with seaborn\n# TODO: Find correlations with p-value < 0.05\n# TODO: Identify multicollinearity issues",
              "expectedOutput": "Correlation matrix heatmap + list of significant correlations"
            }
          ],
          "videoResources": [
            {
              "title": "StatQuest - Hypothesis Testing",
              "url": "https://www.youtube.com/watch?v=0oc49DyA3hU",
              "duration": "12 min",
              "description": "Clear explanation of p-values and significance"
            },
            {
              "title": "Khan Academy - Confidence Intervals",
              "url": "https://www.khanacademy.org/math/statistics-probability/confidence-intervals-one-sample",
              "duration": "25 min",
              "description": "Complete guide to interpreting CIs"
            },
            {
              "title": "3Blue1Brown - Bayes Theorem",
              "url": "https://www.youtube.com/watch?v=HZGCoVF3YvM",
              "duration": "15 min",
              "description": "Visual explanation of statistical inference"
            }
          ],
          "cheatSheet": {
            "descriptive": [
              "Mean: μ = Σx/n - Average",
              "Median: Middle value when sorted",
              "Mode: Most frequent value",
              "Variance: σ² = Σ(x-μ)²/n - Spread",
              "Std Dev: σ = √Variance",
              "IQR: Q3 - Q1 - Robust spread measure"
            ],
            "inferential": [
              "t-test: Compare two means",
              "ANOVA: Compare 3+ means",
              "Chi-square: Categorical associations",
              "Correlation: Linear relationship strength",
              "p-value < 0.05: Statistically significant",
              "95% CI: x̄ ± 1.96×SE (large n)"
            ]
          },
          "commonPitfalls": [
            {
              "mistake": "Confusing correlation with causation",
              "example": "Ice cream sales correlate with drowning deaths",
              "fix": "Correlation doesn't imply causation (confounding: summer heat)"
            },
            {
              "mistake": "p-hacking: Testing until p < 0.05",
              "example": "Try 20 different metrics, one will be significant by chance",
              "fix": "Pre-register hypotheses, correct for multiple comparisons"
            },
            {
              "mistake": "Ignoring sample size",
              "example": "Tiny sample can show \"significant\" result that's not meaningful",
              "fix": "Also check effect size and confidence intervals"
            },
            {
              "mistake": "Using mean for skewed data",
              "example": "Income, housing prices have extreme outliers",
              "fix": "Use median for skewed distributions"
            }
          ],
          "tipsAndTricks": [
            "Always visualize data before statistical tests",
            "Check assumptions (normality, equal variance) before t-test",
            "Use median/IQR for skewed data, mean/std for normal",
            "Report confidence intervals, not just p-values",
            "Effect size matters: statistically significant ≠ practically important",
            "Power analysis: calculate required sample size before experiment"
          ],
          "interactiveExercises": [
            {
              "type": "calculation",
              "question": "Data: [10, 12, 15, 18, 20]. Calculate mean and standard deviation.",
              "hint": "Mean = sum/n, StdDev = √(Σ(x-μ)²/n)",
              "solution": "Mean = 15, StdDev = 3.74",
              "steps": [
                "Mean = (10+12+15+18+20)/5 = 75/5 = 15",
                "Deviations: -5, -3, 0, 3, 5",
                "Squared: 25, 9, 0, 9, 25",
                "Variance = 68/5 = 13.6",
                "StdDev = √13.6 = 3.69"
              ]
            },
            {
              "type": "interpretation",
              "question": "A/B test: p-value = 0.08. Significant at α=0.05?",
              "hint": "Compare p-value to significance level",
              "solution": "No, not significant (0.08 > 0.05)",
              "steps": [
                "α = 0.05 (5% significance level)",
                "p = 0.08 > 0.05",
                "Cannot reject null hypothesis",
                "Difference not statistically significant"
              ]
            }
          ],
          "quiz": [
            {
              "question": "Which measure is most affected by outliers?",
              "options": [
                "Median",
                "Mean",
                "Mode",
                "IQR"
              ],
              "correctAnswer": 1,
              "explanation": "Mean uses all values, so outliers shift it significantly. Median is robust."
            },
            {
              "question": "What does p-value = 0.03 mean?",
              "options": [
                "3% chance hypothesis is true",
                "3% chance of seeing data if null hypothesis true",
                "97% confidence in result",
                "3% error rate"
              ],
              "correctAnswer": 1,
              "explanation": "p-value is probability of observing data (or more extreme) if H₀ is true"
            },
            {
              "question": "A 95% confidence interval [2.1, 3.8] means:",
              "options": [
                "95% of data is in this range",
                "True parameter is definitely in this range",
                "If we repeat sampling, 95% of CIs will contain true parameter",
                "There is 5% error in our estimate"
              ],
              "correctAnswer": 2,
              "explanation": "CI is about the procedure: 95% of intervals from repeated samples contain true value"
            },
            {
              "question": "Correlation r = -0.85 indicates:",
              "options": [
                "Weak negative relationship",
                "Strong negative relationship",
                "No relationship",
                "Moderate positive relationship"
              ],
              "correctAnswer": 1,
              "explanation": "|r| > 0.7 is strong correlation, negative sign shows inverse relationship"
            }
          ]
        }
      }
    ]
  },
  "mr": {
    "topics": [
      {
        "id": "1",
        "title": "रेखीय बीजगणित-वेक्टर आणि मॅट्रिक्स",
        "description": "मशीन लर्निंगचा पाया-वेक्टर, मॅट्रिक्स आणि रेषीय परिवर्तन",
        "estimatedTime": "90 मिनिटे",
        "difficulty": "नवशिक्या",
        "content": {
          "overview": "रेखीय बीजगणित हा यंत्राच्या शिक्षणाचा कणा आहे. डेटा, न्यूरल नेटवर्क्स आणि ऑप्टिमायझेशन अल्गोरिदमसह काम करण्यासाठी वेक्टर आणि मॅट्रिक्स समजून घेणे महत्त्वाचे आहे. * * हे का महत्त्वाचे आहेः * * न्यूरल नेटवर्क्स हे मॅट्रिक्स गुणाकार आहेत. डेटा वेक्टर आणि मॅट्रिक्स म्हणून दर्शविला जातो. प्रधान घटक विश्लेषण (पीसीए) आयगेनव्हॅल्यूज वापरते. प्रतिमा प्रक्रिया मॅट्रिक्स ऑपरेशन्सवर अवलंबून असते",
          "keyPoints": [
            "वेक्टर एन-डायमेन्शनल स्पेसमध्ये डेटा पॉईंट्सचे प्रतिनिधित्व करतात.",
            "मॅट्रिक्स माहितीचे परिवर्तन आणि हाताळणी करतात",
            "डॉट उत्पादन वेक्टरमधील समानता मोजते",
            "मॅट्रिक्स गुणाकार परिवर्तनांचे संयोजन करते.",
            "आयगेनव्हॅल्यूज महत्त्वपूर्ण डेटा नमुने प्रकट करतात",
            "उलटे मॅट्रिक्स रेषीय प्रणालींचे निराकरण करण्यात मदत करतात"
          ],
          "realWorldUseCases": {
            "recommendation": {
              "title": "नेटफ्लिक्स शिफारस प्रणाली",
              "description": "मानांकनाचा अंदाज लावण्यासाठी वापरकर्ता-चित्रपट मॅट्रिक्स फॅक्टरायझेशन",
              "input": "वापरकर्त्याची प्राधान्ये मॅट्रिक्स (वापरकर्ते × चित्रपट)",
              "output": "न पाहिलेल्या चित्रपटांसाठी अंदाजित मानांकन",
              "math": "मॅट्रिक्स फॅक्टरायझेशनः R ≈ U × V ^ T",
              "impact": "लाखो वापरकर्त्यांसाठी वैयक्तिकृत शिफारसी"
            },
            "imageCompression": {
              "title": "प्रतिमा संकुचन (जेपीईजी)",
              "description": "प्रतिमेचा आकार कमी करण्यासाठी एकवचनी मूल्य विघटन",
              "input": "1920 × 1080 प्रतिमा मॅट्रिक्स (2 एम पिक्सेल)",
              "output": "10 टक्के आकारासह संकुचित प्रतिमा",
              "math": "एस. व्ही. डी.: ए = यू × एस × व्ही ^ टी, शीर्ष के एकवचनी मूल्ये ठेवा",
              "impact": "प्रतिमा जलद लोडिंग, कमी साठवण"
            },
            "faceRecognition": {
              "title": "चेहरा ओळखणे (आयगेनफेस)",
              "description": "प्रतिमांमधून चेहऱ्यावरील वैशिष्ट्ये काढणार पी. सी. ए.",
              "input": "उच्च-आयामी वाहक म्हणून चेहऱ्याच्या प्रतिमा",
              "output": "कमी-आयामी वैशिष्ट्य वाहक",
              "math": "सहपरिवर्तन मॅट्रिक्सचे आयगेनव्हॅल्यू अपघटन",
              "impact": "सुरक्षा प्रणालींमध्ये चेहऱ्याचे जलद जुळणी"
            },
            "pageRank": {
              "title": "गुगल पेजरँक अल्गोरिदम",
              "description": "वेब लिंक मॅट्रिक्सचा आयगेनवेक्टर पृष्ठाचे महत्त्व ठरवतो",
              "input": "वेब आलेख संलग्नता मॅट्रिक्स",
              "output": "प्रत्येक वेबपृष्ठासाठीचे महत्त्वाचे गुण",
              "math": "संक्रमण मॅट्रिक्सचा प्रबळ आयगेनवेक्टर शोधा",
              "impact": "शोध परिणामांसाठी अब्जावधी वेबपृष्ठांची क्रमवारी"
            }
          },
          "mathematicalFoundations": [
            {
              "concept": "वेक्टर ऑपरेशन्स",
              "formula": "v1w1 + v2w2 +... + vnwn",
              "explanation": "बिंदू उत्पादः घटकनिहाय गुणाकारांची बेरीज",
              "application": "दस्तऐवजाच्या तुलनेसाठी कोसाइनची समानता"
            },
            {
              "concept": "मॅट्रिक्स गुणाकार",
              "formula": "(AB) ij = σk AikBkj",
              "explanation": "मॅट्रिक्सचा गुणाकार करून परिवर्तने एकत्र करा",
              "application": "न्यूरल नेटवर्क फॉरवर्ड प्रॉपगेशन"
            },
            {
              "concept": "आयगेनव्हॅल्यूज आणि आयगेनवेक्टर्स",
              "formula": "Av2 = λv2",
              "explanation": "केवळ परिवर्तनाखाली मोजमाप करणारे विशेष वाहक",
              "application": "पी. सी. ए. ला जास्तीत जास्त भिन्नतेच्या दिशा सापडतात"
            },
            {
              "concept": "मॅट्रिक्स उलट",
              "formula": "ए. ए.-1 = आय",
              "explanation": "उलट मॅट्रिक्स परिवर्तन पूर्ववत करते",
              "application": "रेखीय प्रतिगमन सोडवणेः θ = (X ^ TX) −1 X ^ Ty"
            }
          ],
          "codeExamples": [
            {
              "title": "वेक्टर ऑपरेशन्स-कोसाईन समानता",
              "language": "python",
              "explanation": "वाहक वापरून दोन कागदपत्रांमधील समानतेची गणना करा.",
              "code": "import numpy as np\n\n# Document vectors (word frequencies)\ndoc1 = np.array([2, 3, 1, 0, 5])  # \"AI is amazing\"\ndoc2 = np.array([1, 2, 1, 1, 4])  # \"ML is great\"\n\n# Cosine similarity: cos(θ) = (v·w) / (|v||w|)\ndot_product = np.dot(doc1, doc2)\nmagnitude1 = np.linalg.norm(doc1)\nmagnitude2 = np.linalg.norm(doc2)\n\nsimilarity = dot_product / (magnitude1 * magnitude2)\nprint(f\"Document Similarity: {similarity:.3f}\")\n# Output: 0.982 (very similar)\n\n# Real-world: Google Search uses this to rank pages",
              "realWorldExample": "शोध इंजिने संबंधित दस्तऐवज शोधण्यासाठी कोसाइन समानता वापरतात"
            },
            {
              "title": "मॅट्रिक्स गुणाकार-प्रतिमा परिवर्तन",
              "language": "python",
              "explanation": "मॅट्रिक्स गुणाकार वापरून प्रतिमा फिरवा",
              "code": "import numpy as np\n\n# 2x2 image patch\nimage = np.array([[100, 200],\n                  [150, 250]])\n\n# Rotation matrix (90° clockwise)\ntheta = -np.pi/2\nrotation_matrix = np.array([\n    [np.cos(theta), -np.sin(theta)],\n    [np.sin(theta), np.cos(theta)]\n])\n\n# Apply transformation (simplified)\n# In practice, apply to pixel coordinates\nrotated = rotation_matrix @ image  # @ is matrix multiplication\nprint(rotated)\n\n# Real-world: Data augmentation in image training",
              "realWorldExample": "प्रतिमा वाढीसाठी सी. एन. एन. मॅट्रिक्स ऑप्सचा वापर करतात."
            },
            {
              "title": "आयगेनव्हॅल्यूज-मुख्य घटक विश्लेषण",
              "language": "python",
              "explanation": "भिन्नता राखून ठेवून परिमाण कमी करा",
              "code": "import numpy as np\nfrom sklearn.decomposition import PCA\n\n# High-dimensional data (100 samples, 50 features)\nX = np.random.randn(100, 50)\n\n# PCA: find top 2 principal components\npca = PCA(n_components=2)\nX_reduced = pca.fit_transform(X)\n\nprint(f\"Original shape: {X.shape}\")\nprint(f\"Reduced shape: {X_reduced.shape}\")\nprint(f\"Variance explained: {pca.explained_variance_ratio_}\")\n\n# Mathematics behind PCA:\n# 1. Center data: X_centered = X - mean(X)\n# 2. Covariance matrix: C = X^T X / n\n# 3. Eigendecomposition: C v = λ v\n# 4. Project onto top k eigenvectors\n\n# Real-world: Visualize high-dim data, remove noise",
              "realWorldExample": "चेहरा ओळखणे, डेटा व्हिज्युअलायझेशन, वैशिष्ट्य निष्कर्षणामध्ये वापरले जाते"
            }
          ],
          "practicalAssignments": [
            {
              "title": "एक लहान शिफारस प्रणाली तयार करा",
              "difficulty": "मध्यम.",
              "estimatedTime": "45 मिनिटे",
              "description": "मॅट्रिक्स फॅक्टरायझेशन वापरून चित्रपट शिफारसी तयार करा",
              "tasks": [
                "वापरकर्ता-चित्रपट मानांकन मॅट्रिक्स तयार करा (5 वापरकर्ते × 8 चित्रपट)",
                "एस. व्ही. डी. वापरून सहयोगात्मक गाळणीची अंमलबजावणी करा",
                "न पाहिलेल्या चित्रपटांच्या मानांकनाचा अंदाज लावा",
                "प्रति वापरकर्ता शीर्ष 3 चित्रपटांची शिफारस करा",
                "अंदाज अचूकतेची गणना करा (आर. एम. एस. ई.)"
              ],
              "starterCode": "np म्हणून नंबर आयात करा #वापरकर्ता-चित्रपट मानांकन (0 = पाहिले नाही) मानांकन = np.array ([[5,3,0,1,4,0,0,2], #वापरकर्ता 1 [4,0,0,1,0,3,0,1], #वापरकर्ता 2 [1,1,0,5,0,4,0], #वापरकर्ता 3 [0,0,4,0,0,5,3,0], #वापरकर्ता 4 [0,3,5,0,1,0,0,0,4], #वापरकर्ता 5]) #टोडोः मॅट्रिक्स फॅक्टरायझेशन #टोडोची अंमलबजावणी कराः गहाळ मानकांचा अंदाज करा #टोडोः शिफारसी तयार करा",
              "expectedOutput": "वापरकर्ता 1 शिफारसीः [चित्रपट 3, चित्रपट 6, चित्रपट 7]"
            },
            {
              "title": "एस. व्ही. डी. सह प्रतिमा संकुचन",
              "difficulty": "मध्यम.",
              "estimatedTime": "30 मिनिटे",
              "description": "एकवचनी मूल्य विघटन वापरून प्रतिमा संकुचित करा",
              "tasks": [
                "मॅट्रिक्स म्हणून ग्रेस्केल प्रतिमा भारित करा",
                "एस. व्ही. डी. लागू कराः ए = यू × एस × व्ही ^ टी",
                "शीर्ष k एकवचनी मूल्ये ठेवा (k = 10,50,100)",
                "संकुचित सादरीकरणातून प्रतिमेची पुनर्रचना करा",
                "फाइल आकार आणि दृश्य गुणवत्तेची तुलना करा"
              ],
              "starterCode": "पी. आय. एल. आयात प्रतिमा #लोड प्रतिमा आय. एम. जी. = Image.open ('photo.jpg'). रूपांतरित ('एल') आय. एम. जी. मॅट्रिक्स = np.array (आय. एम. जी.) #टी. ओ. डी. ओ.: एस. व्ही. डी. #टी. ओ. डी. ओ. लागू कराः वेगवेगळ्या के मूल्यांसह पुनर्बांधणी #टी. ओ. डी. ओ.: संकुचन गुणोत्तर मोजा",
              "expectedOutput": "के = 50ः 90 टक्के संकुचन, 95 टक्के गुणवत्ता कायम"
            }
          ],
          "interactiveExercises": [
            {
              "question": "व्ही. बाय. = [2,3,1] आणि डब्ल्यू. बाय. = [1,4,2] च्या बिंदू गुणाकाराची गणना करा.",
              "type": "calculation",
              "hint": "(2 × 1) + (3 × 4) + (1 × 2)",
              "answer": "16.",
              "explanation": "2 × 1 + 3 × 4 + 1 × 2 = 2 + 12 + 2 = 16"
            },
            {
              "question": "पूर्ण स्तंभ श्रेणी असलेल्या 100 × 50 मॅट्रिक्सची श्रेणी किती आहे?",
              "type": "multiple-choice",
              "options": [
                "100.",
                "50.",
                "150.",
                "5000."
              ],
              "answer": "50.",
              "explanation": "रँक = पूर्ण स्तंभासह किमान (पंक्ती, कोल) = 50"
            }
          ],
          "quiz": [
            {
              "question": "न्यूरल नेटवर्कमध्ये, मॅट्रिक्स गुणाकार कशाचे प्रतिनिधित्व करतो?",
              "options": [
                "इनपुटची भारित बेरीज",
                "घटकांनुसार उत्पादन",
                "सक्रियकरण कार्य",
                "नुकसानीची गणना"
              ],
              "correctAnswer": 0,
              "explanation": "मॅट्रिक्स गुणाकार भारित रकमांची गणना करतोः y = Wx + b"
            },
            {
              "question": "मुख्य घटक शोधण्यासाठी पी. सी. ए. काय वापरते?",
              "options": [
                "मॅट्रिक्स उलट्या",
                "आयगेनव्हल्यू अपघटन",
                "ग्रेडियंट डिसेंट",
                "क्रॉस उत्पादन"
              ],
              "correctAnswer": 1,
              "explanation": "पी. सी. ए. ला कोव्हॅरियन्स मॅट्रिक्सचे आयगेनवेक्टर सापडतात (कमाल भिन्नतेच्या दिशा)"
            },
            {
              "question": "कोसाइनची समानता खालीलप्रमाणे आहेः",
              "options": [
                "0 ते 1",
                "- 1 ते 1",
                "0 ते φ",
                "- φ ते φ"
              ],
              "correctAnswer": 1,
              "explanation": "कोसाइन समानता = कोस (कोन)-1 (विरुद्ध) ते 1 (समान) पर्यंत आहे"
            }
          ]
        }
      },
      {
        "id": "2",
        "title": "गणिती-व्युत्पन्न आणि प्रवणता",
        "description": "न्यूरल नेटवर्क्स डेरिव्हेटिव्ह्ज आणि बॅकप्रोपेगेशनद्वारे कसे शिकतात हे समजून घेणे",
        "estimatedTime": "75 मिनिटे",
        "difficulty": "मध्यवर्ती",
        "content": {
          "overview": "कॅल्क्युलस हे बदलाचे गणित आहे. मशीन लर्निंगमध्ये, त्रुटी कमी करण्यासाठी पॅरामीटर्स कसे समायोजित करावे हे शोधून मॉडेल ऑप्टिमाइझ करण्यासाठी आपण डेरिव्हेटिव्ह्ज वापरतो. * * हे का महत्त्वाचे आहेः * * ग्रेडियंट डिसेंट नुकसान कमी करण्यासाठी डेरिव्हेटिव्ह्जचा वापर करतो; बॅकप्रोपेगेशन साखळी नियमांद्वारे ग्रेडियंटची गणना करतो; ऑप्टिमायझेशन अल्गोरिदम कॅल्क्युलसवर अवलंबून असतात; शिकण्याचे दर समजून घेण्यासाठी डेरिव्हेटिव्ह्जची आवश्यकता असते",
          "keyPoints": [
            "व्युत्पन्न उपाय बदलाचा दर",
            "सर्वात तीव्र वाढीच्या दिशेने उतार बिंदू",
            "साखळी नियम बॅकप्रोपेगेशन सक्षम करतो",
            "आंशिक व्युत्पन्न बहु-चल कार्ये हाताळतात",
            "दुसरे व्युत्पन्न वक्रता दर्शवतात (हेसियन)",
            "टेलर मालिका अंदाजे जटिल कार्ये"
          ],
          "realWorldUseCases": {
            "neuralNetworkTraining": {
              "title": "खोल न्यूरल नेटवर्कचे प्रशिक्षण",
              "description": "बॅकप्रोपेगेशन ग्रेडियंटची गणना करण्यासाठी साखळी नियम वापरते",
              "input": "जाळ्याचे वजन, प्रशिक्षण डेटा बॅच",
              "output": "ग्रेडियंट डिसेंटद्वारे अद्ययावत केलेले वजन",
              "math": "ष्णू नुकसान/ष्णू डब्ल्यू = ष्णू नुकसान/ष्णू उत्पादन × ष्णू उत्पादन/ष्णू डब्ल्यू",
              "impact": "अब्जावधी मापदंडांसह (जी. पी. टी., बी. ई. आर. टी.) गाड्यांचे मॉडेल"
            },
            "selfDrivingCars": {
              "title": "सेल्फ-ड्रायव्हिंग कार ऑप्टिमायझेशन",
              "description": "गणिताचा वापर करून प्रक्षेपवक्र खर्चाचे कार्य कमी करा",
              "input": "सध्याची स्थिती, गंतव्य, अडथळे",
              "output": "इष्टतम सुकाणू/प्रवेग आदेश",
              "math": "कमी कराः सी (एक्स) = सुरक्षा _ किंमत + कार्यक्षमता _ किंमत + आराम _ किंमत",
              "impact": "सुरक्षित, सुरळीत स्वयंचलित वाहन चालवणे"
            },
            "stockTrading": {
              "title": "अल्गोरिदमिक व्यापार",
              "description": "जोखीम/परताव्याचे डेरिव्हेटिव्ह वापरून पोर्टफोलिओ अनुकूल करा",
              "input": "समभागांच्या किंमती, जोखीम सहनशीलता",
              "output": "इष्टतम मालमत्ता वाटप",
              "math": "कमाल कराः E [परतावा]-λ × वार [परतावा]",
              "impact": "स्वयंचलित व्यापारात दररोज कोट्यवधी"
            },
            "imageUpscaling": {
              "title": "ए. आय. प्रतिमा सुपर-रिझोल्यूशन",
              "description": "आकलनशक्तीची हानी कमी करून उच्च-रिझोल्यूशन प्रतिमा तयार करा",
              "input": "कमी रिझोल्यूशनची प्रतिमा",
              "output": "उच्च-रिझोल्यूशन प्रतिमा",
              "math": "ग्रेडियंट डिसेंटचा वापर करून आकलनशक्तीची हानी कमी करा",
              "impact": "जुने छायाचित्र सुधारणे, चित्रफितीची गुणवत्ता सुधारणे"
            }
          },
          "mathematicalFoundations": [
            {
              "concept": "व्युत्पन्न",
              "formula": "एफ'(एक्स) = लिम (एच → 0) [एफ (एक्स + एच)-एफ (एक्स)]/एच",
              "explanation": "बदलाचा तात्काळ दर",
              "application": "वजन समायोजित केल्याने वजन कमी होण्यात किती बदल होतो?"
            },
            {
              "concept": "साखळी नियम",
              "formula": "ष्णू/ष्णू = (ष्णू/ष्णू) × (ष्णू/ष्णू)",
              "explanation": "संमिश्र कार्ये व्युत्पन्न",
              "application": "मज्जासंस्थेच्या जाळ्याच्या थरांद्वारे बॅकप्रोपेगेशन"
            },
            {
              "concept": "ग्रेडियंट",
              "formula": "ρf = [ष्णू f/ष्णू x1, ष्णू f/ष्णू x2,..., ष्णू f/ष्णू xn]",
              "explanation": "सर्व आंशिक डेरिव्हेटिव्ह्जचे वाहक",
              "application": "पॅरामीटर जागेत हलवण्याची दिशा"
            },
            {
              "concept": "टेलर मालिका",
              "formula": "f (x) ≈ f (a) + f'(a) (x-a) + f \"(a) (x-a) 2/2! +..",
              "explanation": "बहुपदीसह अंदाजे कार्ये",
              "application": "दुसऱ्या क्रमांकाच्या इष्टतम पद्धती (न्यूटनची पद्धत)"
            }
          ],
          "codeExamples": [
            {
              "title": "ग्रेडियंट डिसेंट-रेखीय प्रतिगमन",
              "language": "python",
              "explanation": "सर्वोत्तम जुळणारी रेषा शोधण्यासाठी डेरिव्हेटिव्ह वापरा",
              "code": "import numpy as np\nimport matplotlib.pyplot as plt\n\n# Generate data: y = 3x + 2 + noise\nnp.random.seed(42)\nX = np.linspace(0, 10, 100)\ny = 3 * X + 2 + np.random.randn(100) * 2\n\n# Initialize parameters\nw = 0.0  # slope\nb = 0.0  # intercept\nlearning_rate = 0.01\nepochs = 100\n\n# Gradient descent\nfor epoch in range(epochs):\n    # Predictions\n    y_pred = w * X + b\n    \n    # Loss: Mean Squared Error\n    loss = np.mean((y_pred - y) ** 2)\n    \n    # Gradients (derivatives of loss)\n    dw = 2 * np.mean((y_pred - y) * X)\n    db = 2 * np.mean(y_pred - y)\n    \n    # Update parameters\n    w -= learning_rate * dw\n    b -= learning_rate * db\n    \n    if epoch % 20 == 0:\n        print(f\"Epoch {epoch}: Loss={loss:.3f}, w={w:.3f}, b={b:.3f}\")\n\nprint(f\"\\nFinal: w={w:.3f} (true=3), b={b:.3f} (true=2)\")",
              "realWorldExample": "घरांच्या किंमतींचा अंदाज, समभागांचा कल, विक्रीचा अंदाज"
            },
            {
              "title": "बॅकप्रोपेगेशन-साधे मज्जासंस्थेचे जाळे",
              "language": "python",
              "explanation": "थरांद्वारे ग्रेडियंटची गणना करण्यासाठी साखळी नियम",
              "code": "import numpy as np\n\ndef sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n\ndef sigmoid_derivative(x):\n    return x * (1 - x)\n\n# Input and output\nX = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\ny = np.array([[0], [1], [1], [0]])  # XOR problem\n\n# Initialize weights\nnp.random.seed(1)\nw1 = np.random.randn(2, 2)  # Input to hidden\nw2 = np.random.randn(2, 1)  # Hidden to output\n\nlearning_rate = 1.0\n\n# Training\nfor epoch in range(10000):\n    # Forward pass\n    layer1 = sigmoid(X @ w1)\n    output = sigmoid(layer1 @ w2)\n    \n    # Backward pass (chain rule!)\n    error = y - output\n    d_output = error * sigmoid_derivative(output)\n    \n    # Chain rule: ∂L/∂w2 = ∂L/∂output × ∂output/∂w2\n    error_layer1 = d_output @ w2.T\n    d_layer1 = error_layer1 * sigmoid_derivative(layer1)\n    \n    # Update weights\n    w2 += layer1.T @ d_output * learning_rate\n    w1 += X.T @ d_layer1 * learning_rate\n\nprint(\"Predictions (should be near [0, 1, 1, 0]):\")\nprint(output.round(2))",
              "realWorldExample": "प्रतिमा ओळख, भाषा प्रतिकृतींसाठी सखोल जाळे तयार करण्याचे प्रशिक्षण"
            }
          ],
          "practicalAssignments": [
            {
              "title": "मिनी-बॅच ग्रेडियंट डिसेंटची अंमलबजावणी करा",
              "difficulty": "मध्यम.",
              "estimatedTime": "40 मिनिटे",
              "description": "मिनी-बॅच अद्ययावतांसह ट्रेन लॉजिस्टिक रिग्रेशन",
              "tasks": [
                "द्वैती वर्गीकरण डेटासेट तयार करा",
                "सिग्मॉइड सक्रियण कार्यान्वित करा",
                "क्रॉस-एन्ट्रॉपी हानीची गणना करा",
                "छोट्या तुकड्यांसाठी प्रवणतेची गणना करा",
                "वजन आणि ट्रॅक अभिसरण अद्ययावत करा"
              ],
              "starterCode": "संख्या एन. पी. म्हणून आयात करा #टोडोः डेटासेट तयार करा (sklearn.make_classification) #टोडोः सिग्मॉइडची अंमलबजावणी करा (झेड) = 1/(1 + ई-झेड) #टोडोः नुकसान =-म्हणजे (वाय * लॉग (प्रिड) + (1-वाय) * लॉग (1-प्रिड)) #टोडोः ग्रेडियंट = एक्स. टी. (प्रिड-वाय)/बॅच _ साइज #टोडोः बॅच _ साइज = 32 सह प्रशिक्षण, लर्निंग _ रेट = 0.01",
              "expectedOutput": "अचूकताः 95 टक्के +, नुकसान सुरळीतपणे एकत्रित होते"
            }
          ],
          "quiz": [
            {
              "question": "ग्रेडियंट वेक्टर कोणत्या दिशेने निर्देश करतो?",
              "options": [
                "सर्वात तीव्र घसरणीची दिशा",
                "सर्वाधिक वाढीची दिशा",
                "किमान कार्य",
                "यादृच्छिक दिशा"
              ],
              "correctAnswer": 1,
              "explanation": "उतार वरच्या दिशेने निर्देशित करतो (वाढतो). कमी करण्यासाठी आपण-उतार दिशेने सरकतो."
            },
            {
              "question": "बॅकप्रोपेगेशनमध्ये, गणिताचा कोणता नियम ग्रेडियंटची गणना करण्यास सक्षम करतो?",
              "options": [
                "उत्पादनाचा नियम",
                "साखळी नियम",
                "प्रमाण नियम",
                "सत्तेचा नियम"
              ],
              "correctAnswer": 1,
              "explanation": "साखळी नियमः ष्णू f/ष्णू x = (ष्णू f/ष्णू) (ष्णू/ष्णू x) थरांद्वारे मागे सरकणाऱ्या प्रवाहाचा प्रसार करते."
            }
          ]
        }
      },
      {
        "id": "3",
        "title": "संभाव्यता सिद्धांत-एम. एल. चा पाया",
        "description": "संभाव्यतेचे वितरण, बेयस प्रमेय आणि अनिश्चिततेचे प्रमाण समजून घ्या",
        "estimatedTime": "80 मिनिटे",
        "difficulty": "मध्यवर्ती",
        "content": {
          "overview": "यंत्र शिक्षणासाठी संभाव्यता ही मूलभूत बाब आहे. वर्गीकरणाचे परिणाम संभाव्यतेचे, वितरणाचे जनरेटिव्ह मॉडेल्सचे नमुने, आणि बायेसियन पद्धती अनिश्चिततेचे प्रमाण ठरवतात. * * हे का महत्त्वाचे आहेः * * सॉफ्टमॅक्स गुणांचे संभाव्यतेमध्ये रूपांतर करते; नॅव्ह बेयस वर्गीकरण सशर्त संभाव्यतेचा वापर करते; जनरेटिव्ह मॉडेल्स (जी. ए. एन., व्ही. ए. ई.) वितरण शिकतात; अंदाजांमध्ये अनिश्चिततेचा अंदाज",
          "keyPoints": [
            "संभाव्यता घटनांची संभाव्यता मोजते (0 ते 1)",
            "सशर्त संभाव्यताः पी (A|B) = पी (ए θ बी)/पी (बी)",
            "बेयसचे प्रमेय पुराव्यांसह समजुतींना अद्ययावत करते",
            "वितरण मॉडेल यादृच्छिक चल",
            "अपेक्षित मूल्य भारित सरासरी आहे",
            "स्वातंत्र्य गणना सुलभ करते"
          ],
          "realWorldUseCases": {
            "spamFilter": {
              "title": "ईमेल स्पॅम शोध (नॅव्ह बेयस)",
              "description": "संभाव्यतेची गणना करा ईमेल हे स्पॅम दिलेले शब्द आहेत",
              "input": "ईमेल मजकूरः \"विनामूल्य विजेता! आता क्लिक करा!\"",
              "output": "पी (Spam|words) = 0.95 → स्पॅम",
              "math": "पी (Spam|words) = पी (words|Spam) × पी (स्पॅम)/पी (शब्द)",
              "impact": "दररोज कोट्यवधी स्पॅम ईमेल फिल्टर करते"
            },
            "medicalDiagnosis": {
              "title": "बेयस प्रमेय वापरून रोगाचे निदान",
              "description": "सकारात्मक चाचणीनंतर रोगाची संभाव्यता अद्ययावत करा",
              "input": "चाचणीचा सकारात्मक निकाल, रोगाचा प्रादुर्भाव 1 टक्के",
              "output": "आजार होण्याची खरी शक्यता",
              "math": "पी (रोग। +) = पी (+ |Disease) × पी (रोग)/पी (+)",
              "impact": "चुकीचे सकारात्मक निर्णय असूनही अचूक वैद्यकीय निर्णय"
            },
            "weatherForecasting": {
              "title": "हवामानाची शक्यता",
              "description": "एकत्रित मॉडेल आउटपुट संभाव्यता वितरण",
              "input": "तापमान, दाब, आर्द्रता माहिती",
              "output": "पी (उद्या पाऊस) = 0.73",
              "math": "अनेक नमुन्यांचे अंदाज वजनासह एकत्र करा",
              "impact": "कृषी, विमान वाहतुकीसाठी विश्वासार्ह अंदाज"
            },
            "recommendationSystems": {
              "title": "नेटफ्लिक्स सामग्री शिफारसी",
              "description": "संभाव्य वापरकर्त्याला इतिहासावर आधारित वस्तू आवडेल",
              "input": "वापरकर्ता बघण्याचा इतिहास, वस्तूची वैशिष्ट्ये",
              "output": "पी (वापरकर्त्याला चित्रपट आवडतो। वैशिष्ट्ये) = 0.88",
              "math": "संभाव्य मॅट्रिक्स फॅक्टरायझेशनसह सहयोगी फिल्टरिंग",
              "impact": "200 एम + ग्राहकांसाठी वैयक्तिकृत सामग्री"
            }
          },
          "mathematicalFoundations": [
            {
              "concept": "मूलभूत संभाव्यता",
              "formula": "पी (ए) = अनुकूल परिणाम/एकूण परिणाम",
              "explanation": "सर्व संभाव्य घटनांमध्ये इच्छित घटनांचे प्रमाण",
              "application": "नाणे पलटीः पी (हेड्स) = 1/2, पासाः पी (6) = 1/6"
            },
            {
              "concept": "सशर्त संभाव्यता",
              "formula": "पी (A|B) = पी (ए θ बी)/पी (बी)",
              "explanation": "अ दिलेल्या ब ची संभाव्यता उद्भवली आहे",
              "application": "ईमेल फिल्टरिंगमध्ये पी (स्पॅम। मध्ये \"मोफत\" समाविष्ट आहे)"
            },
            {
              "concept": "बेयस प्रमेय",
              "formula": "पी (A|B) = पी (B|A) × पी (ए)/पी (बी)",
              "explanation": "ब पुराव्यासह पी (ए) वरील पूर्वविश्वास अद्ययावत करा",
              "application": "वैद्यकीय निदान, स्पॅम वर्गीकरण, ए/बी चाचणी"
            },
            {
              "concept": "अपेक्षित मूल्य",
              "formula": "ई [एक्स] = x × पी (एक्स = एक्स)",
              "explanation": "सर्व संभाव्य मूल्यांची भारित सरासरी",
              "application": "वित्तपुरवठ्यातील अपेक्षित परतावा, सरासरी अंदाज त्रुटी"
            },
            {
              "concept": "स्वातंत्र्य",
              "formula": "पी (ए θ बी) = पी (ए) × पी (बी)",
              "explanation": "घटना एकमेकांवर परिणाम करत नाहीत",
              "application": "नॅव्ह बेयसने वैशिष्ट्यपूर्ण स्वातंत्र्य स्वीकारले"
            },
            {
              "concept": "एकूण संभाव्यतेचा नियम",
              "formula": "पी (ए) = पी (A|Bᵢ) × पी (बीआय)",
              "explanation": "सर्व संभाव्य अटींची बेरीज",
              "application": "संभाव्य प्रतिकृतींमधील चलांची संख्या कमी करणे"
            }
          ],
          "distributions": {
            "discrete": [
              {
                "name": "Bernoulli",
                "formula": "पी (एक्स = 1) = पी, पी (एक्स = 0) = 1-पी",
                "description": "दोन परिणामांसह एकच चाचणी (यश/अपयश)",
                "example": "नाणे उलटणे, द्वैती वर्गीकरण",
                "parameters": "पी (यशाची संभाव्यता)"
              },
              {
                "name": "Binomial",
                "formula": "पी (एक्स = के) = सी (एन, के) × पी × के × (1-पी)",
                "description": "स्वतंत्र चाचण्यांमधील यशांची संख्या",
                "example": "10 नाण्यांच्या पलटीतील शिरोबिंदूची संख्या",
                "parameters": "एन (चाचण्या), पी (यश मिळण्याची शक्यता)"
              },
              {
                "name": "Poisson",
                "formula": "पी (एक्स = के) = (λ ^ के × ई ^ (-λ))/के!",
                "description": "निश्चित मध्यांतरातील घटनांची संख्या",
                "example": "प्रति तास संकेतस्थळ भेटी, ग्राहकांचे आगमन",
                "parameters": "λ (सरासरी दर)"
              }
            ],
            "continuous": [
              {
                "name": "Normal (Gaussian)",
                "formula": "f (x) = (1/α (2πσ2)) × e ^ (-(x-α) 2/(2σ2))",
                "description": "घंटा वक्र-सर्वात सामान्य वितरण",
                "example": "उंची, बुद्ध्यांक, मापन त्रुटी",
                "parameters": "μ (मीन), σ (एसटीडी विचलन)",
                "properties": "68-95-99.7 नियमः 1सी. एम. मध्ये 68 टक्के, 2सी. एम. मध्ये 95 टक्के, 3सी. एम. मध्ये 99.7%"
              },
              {
                "name": "Uniform",
                "formula": "x साठी f (x) = 1/(b-a) [a, b]",
                "description": "सर्व परिणामांची समान शक्यता",
                "example": "यादृच्छिक संख्या निर्मिती, डाइस रोल",
                "parameters": "अ (किमान), ब (कमाल)"
              },
              {
                "name": "Exponential",
                "formula": "x ≤ 0 साठी f (x) = λe ^ (-λx)",
                "description": "घटना घडण्यापर्यंतची वेळ",
                "example": "ग्राहकांच्या आगमनातील वेळ, किरणोत्सर्गी क्षय",
                "parameters": "λ (दर)"
              }
            ]
          },
          "codeExamples": [
            {
              "title": "बेयस प्रमेय-स्पॅम फिल्टर",
              "language": "python",
              "explanation": "ईमेलचे स्पॅम म्हणून वर्गीकरण करण्यासाठी बेयस वापरा किंवा नाही",
              "code": "import numpy as np\n\n# Spam filter example\nprint(\"=== Email Spam Classification ===\\n\")\n\n# Prior probabilities\nP_spam = 0.3  # 30% of emails are spam\nP_ham = 0.7   # 70% are legitimate\n\n# Likelihood: P(word | class)\n# Word \"free\" appears in:\nP_free_given_spam = 0.8  # 80% of spam\nP_free_given_ham = 0.1   # 10% of legitimate\n\n# Email contains \"free\" - what's P(Spam | \"free\")?\n\n# Law of total probability: P(\"free\")\nP_free = P_free_given_spam * P_spam + P_free_given_ham * P_ham\nprint(f'P(\"free\") = {P_free:.3f}')\n\n# Bayes Theorem\nP_spam_given_free = (P_free_given_spam * P_spam) / P_free\nprint(f'P(Spam | \"free\") = {P_spam_given_free:.3f}')\nprint(f'P(Ham | \"free\") = {1 - P_spam_given_free:.3f}')\n\nprint(f'\\n→ Email with \"free\" is {P_spam_given_free:.1%} likely spam')",
              "realWorldExample": "जीमेल दरवर्षी 100 बी + स्पॅम ईमेल फिल्टर करते"
            },
            {
              "title": "संभाव्यता वितरण",
              "language": "python",
              "explanation": "सामान्य संभाव्यता वितरणांसह कार्य करा",
              "code": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\n# 1. Binomial: Coin flips\nn, p = 10, 0.5  # 10 flips, fair coin\nbinomial = stats.binom(n, p)\nprint(\"Binomial(n=10, p=0.5):\")\nprint(f\"  P(X=5) = {binomial.pmf(5):.4f}\")\nprint(f\"  P(X≤7) = {binomial.cdf(7):.4f}\")\nprint(f\"  Mean = {binomial.mean():.1f}\")\nprint(f\"  Std = {binomial.std():.2f}\")\n\n# 2. Normal: IQ scores\nmu, sigma = 100, 15  # IQ distribution\nnormal = stats.norm(mu, sigma)\nprint(f\"\\nNormal(μ={mu}, σ={sigma}):\")\nprint(f\"  P(X < 115) = {normal.cdf(115):.4f}\")\nprint(f\"  P(85 < X < 115) = {normal.cdf(115) - normal.cdf(85):.4f}\")\nprint(f\"  95th percentile = {normal.ppf(0.95):.1f}\")\n\n# 3. Poisson: Website visits\nlambda_rate = 5  # 5 visits per hour\npoisson = stats.poisson(lambda_rate)\nprint(f\"\\nPoisson(λ={lambda_rate}):\")\nprint(f\"  P(X=5) = {poisson.pmf(5):.4f}\")\nprint(f\"  P(X≥3) = {1 - poisson.cdf(2):.4f}\")",
              "realWorldExample": "ए/बी चाचणी, गुणवत्ता नियंत्रण, जोखीम मूल्यांकन"
            },
            {
              "title": "स्क्रॅच मधील निष्काळजी बेयस वर्गीकरण",
              "language": "python",
              "explanation": "संभाव्यतेचा वापर करून स्पॅम वर्गीकरण तयार करा",
              "code": "import numpy as np\n\nclass NaiveBayes:\n    def fit(self, X, y):\n        n_samples, n_features = X.shape\n        self.classes = np.unique(y)\n        \n        # Prior: P(class)\n        self.priors = {}\n        # Likelihood: P(feature | class)\n        self.mean = {}\n        self.var = {}\n        \n        for c in self.classes:\n            X_c = X[y == c]\n            self.priors[c] = len(X_c) / n_samples\n            self.mean[c] = X_c.mean(axis=0)\n            self.var[c] = X_c.var(axis=0)\n    \n    def _pdf(self, x, mean, var):\n        # Gaussian probability density\n        return np.exp(-((x - mean)**2) / (2*var)) / np.sqrt(2*np.pi*var)\n    \n    def predict(self, X):\n        predictions = []\n        for x in X:\n            posteriors = {}\n            for c in self.classes:\n                # Prior\n                prior = np.log(self.priors[c])\n                # Likelihood (assuming independence)\n                likelihood = np.sum(np.log(self._pdf(x, self.mean[c], self.var[c])))\n                # Posterior ∝ Prior × Likelihood\n                posteriors[c] = prior + likelihood\n            predictions.append(max(posteriors, key=posteriors.get))\n        return np.array(predictions)\n\n# Test on iris dataset\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\n\niris = load_iris()\nX_train, X_test, y_train, y_test = train_test_split(\n    iris.data, iris.target, test_size=0.3, random_state=42\n)\n\nnb = NaiveBayes()\nnb.fit(X_train, y_train)\npredictions = nb.predict(X_test)\naccuracy = np.mean(predictions == y_test)\nprint(f\"Accuracy: {accuracy:.1%}\")",
              "realWorldExample": "मजकुराचे वर्गीकरण, भावना विश्लेषण, वैद्यकीय निदान"
            }
          ],
          "practicalAssignments": [
            {
              "title": "वैद्यकीय निदान प्रणाली तयार करा",
              "difficulty": "मध्यम.",
              "estimatedTime": "50 मिनिटे",
              "description": "रोगाच्या संभाव्यतेची गणना करण्यासाठी बेयस प्रमेय वापरा",
              "tasks": [
                "बेयस प्रमेय कार्य कार्यान्वित करा",
                "दिलेल्या प्रादुर्भाव आणि चाचणीच्या अचूकतेसह पी (रोग। + चाचणी) ची गणना करा.",
                "अनेक चाचण्यांचे निकाल हाताळा (संभाव्यता पुन्हा पुन्हा अद्ययावत करा)",
                "पुराव्यांसह नंतरचे कसे बदलतात याची कल्पना करा",
                "पूर्वीच्या वेगवेगळ्या संभाव्यतेसह चाचणी करा"
              ],
              "starterCode": "इम्पोर्ट नंपी म्हणून एन. पी. डेफ बेयस _ अपडेट (पूर्व, संभाव्यता _ सत्य, संभाव्यता _ असत्य, पुरावा = सत्य): \"बेयस प्रमेय वापरून संभाव्यता अद्ययावत करा. आर्ग्सः पूर्वः पी (रोग) संभाव्यता _ सत्यः पी (+ चाचणी। रोग) संभाव्यता _ असत्यः पी (+ चाचणी। रोग नाही) पुरावाः चाचणी सकारात्मक परत आल्यास सत्यः नंतरची संभाव्यता पी (रोग। चाचणी)\" #टोडोः बेयस प्रमेय लागू करा #पी (रोग। +) = पी (+। रोग) * पी (रोग)/पी (+) #जेथे पी (+) = पी (+। रोग) * पी (रोग) + पी (+। रोग नाही) * पी (रोग नाही) * पी (रोग नाही) पास #उदाहरणेः दुर्मिळ रोग (1 टक्के प्रसार), अचूक चाचणी #टीओडीओडीः 99 टक्के अचूक चाचणी #टीओडीओडी",
              "expectedOutput": "पी (रोग। + चाचणी) ≈ 0.50 (0.99 नाही!), आधार दराची विसंगती दर्शवते"
            },
            {
              "title": "मोंटे कार्लो अनुकरण",
              "difficulty": "सोपी.",
              "estimatedTime": "30 मिनिटे",
              "description": "यादृच्छिक नमुन्यांद्वारे संभाव्यतेचा अंदाज लावा",
              "tasks": [
                "10, 000 फासे गुंडाळण्याचे अनुकरण करा",
                "दोन फासे सह बेरीज = 7 ची अंदाजित संभाव्यता",
                "अनुभवजन्य विरुद्ध सैद्धांतिक संभाव्यतेची गणना करा",
                "परिणामांच्या वितरणाची कल्पना करा",
                "अंदाजासाठी विश्वासाच्या मध्यांतरांची गणना करा"
              ],
              "starterCode": "इम्पोर्ट नंपी एन. पी. म्हणून #टोडोः दोन फासे 10,000 वेळा फिरवण्याचे अनुकरण करा #टोडोः बेरीज किती वेळा 7 च्या बरोबरीची आहे ते मोजा #टोडोः सैद्धांतिक पी. शी तुलना करा (बेरीज = 7) = 6/36 #सैद्धांतिकः (1,6), (2,5), (3,4), (4,3), (5,2), (6,1)",
              "expectedOutput": "अनुभवजन्य संभाव्यता ≈ 0.167, सैद्धांतिक 6/36 ≈ 0.167 च्या जवळ"
            }
          ],
          "videoResources": [
            {
              "title": "3 ब्ल्यू 1 ब्राऊन-बेयस प्रमेय दृश्यमान",
              "url": "https://www.youtube.com/watch?v=HZGCoVF3YvM",
              "duration": "15 मिनिटे",
              "description": "बेयस प्रमेयचे सुंदर दृश्य स्पष्टीकरण"
            },
            {
              "title": "स्टॅटक्युएस्ट-संभाव्यता वितरण",
              "url": "https://www.youtube.com/watch?v=rzFX5NWojp0",
              "duration": "10 मिनिटे",
              "description": "सामान्य वितरणांचा स्पष्ट परिचय"
            },
            {
              "title": "खान अकादमी-सशर्त संभाव्यता",
              "url": "https://www.khanacademy.org/math/statistics-probability/probability-library",
              "duration": "30 मिनिटे",
              "description": "पूर्ण संभाव्यता मूलभूत अभ्यासक्रम"
            }
          ],
          "cheatSheet": {
            "formulas": [
              "पी (A|B) = पी (ए θ बी)/पी (बी)-सशर्त संभाव्यता",
              "पी (A|B) = पी (B|A) पी (ए)/पी (बी)-बेयस प्रमेय",
              "पी (ए ≤ बी) = पी (ए) + पी (बी)-पी (ए ≤ बी)-संघ",
              "पी (ए θ बी) = पी (ए) पी (बी) स्वतंत्र असल्यास",
              "E [X] = σx·P (x)-अपेक्षित मूल्य",
              "वार (एक्स) = ई [एक्स 2]-ई [एक्स] 2-भिन्नता"
            ],
            "distributions": [
              "बर्नौली (पी): द्वैती परिणाम",
              "द्विपदी (एन, पी): एन चाचण्या, गणना यश",
              "पॉइसन (λ): मध्यांतरातील घटना",
              "नॉर्मल (μ, σ): बेल कर्व, 68-95-99.7 नियम",
              "एकसमान (अ, ब): समान संभाव्यता",
              "घातांकीय (λ): घटनेपर्यंतचा वेळ"
            ]
          },
          "commonPitfalls": [
            {
              "mistake": "पी (A|B) आणि पी (B|A) यांचा गोंधळ",
              "example": "पी (सकारात्मक चाचणी। रोग) ष्णू पी (रोग। सकारात्मक चाचणी)",
              "fix": "सशर्त संभाव्यता उलटवण्यासाठी नेहमी बेयस प्रमेय वापरा"
            },
            {
              "mistake": "वैशिष्ट्ये परस्परसंबंधित असताना स्वातंत्र्य गृहीत धरणे",
              "example": "नॅव्ह बेयस सर्व वैशिष्ट्ये स्वतंत्रपणे गृहीत धरतो",
              "fix": "परस्परसंबंध मॅट्रिक्स तपासा, अवलंबित्वांचा विचार करा"
            },
            {
              "mistake": "आधारभूत दरांकडे दुर्लक्ष करणे (पूर्व शक्यता)",
              "example": "दुर्मिळ रोगः अगदी अचूक चाचणी → कमी पी (रोग। +)",
              "fix": "गणनेत नेहमी पी (रोग) समाविष्ट करा."
            },
            {
              "mistake": "संभाव्यता चुकीच्या पद्धतीने जोडणे",
              "example": "पी (ए ≤ बी) = पी (ए) + पी (बी) केवळ परस्पर अनन्य असल्यास",
              "fix": "पी (ए ≤ बी) = पी (ए) + पी (बी)-पी (ए ≤ बी) वापरा"
            }
          ],
          "tipsAndTricks": [
            "गुंतागुंतीच्या समस्यांसाठी संभाव्यता झाडे काढा",
            "सूत्रे कठीण असताना अनुकरण (मोंटे कार्लो) वापरा",
            "पी (एकूण) = 1 आहे का ते तपासा (संभाव्यतेची बेरीज 1 असणे आवश्यक आहे)",
            "लॉग संभाव्यता संख्यात्मक अधोगती रोखते",
            "शेवटी सामान्य कराः पी (A|B) ꯘꯥ पी (B|A) पी (ए)",
            "सामान्य वितरणासाठी 68-95-99.7 नियम लक्षात ठेवा"
          ],
          "interactiveExercises": [
            {
              "type": "calculation",
              "question": "एका पिशवीत 3 लाल, 2 निळे चेंडू असतात. बदली न करता 2 निवडा. पी (दोन्ही लाल)?",
              "hint": "पी (आर 1 ≤ आर 2) = पी (आर 1) × पी (आर 2 |R 1)",
              "solution": "(3/5) × (2/4) = 6/20 = 0.3",
              "steps": [
                "पी (आर 1) = 3/5",
                "1 लाल घेतल्यानंतर, 4 पैकी 2 लाल राहतात.",
                "पी (आर2 |R 1) = 2/4",
                "गुणाकारः (3/5) (2/4) = 0.3"
              ]
            },
            {
              "type": "calculation",
              "question": "रोग 2 टक्के लोकसंख्येला प्रभावित करतो. चाचणीः 95 टक्के संवेदनशील, 90 टक्के विशिष्ट. तुमची चाचणी पॉझिटिव्ह. पी (रोग)?",
              "hint": "बेयस वापराः पी (डी। +) = पी (+ |D) पी (डी)/पी (+)",
              "solution": "पी (डी। +) ≈ 0.161 किंवा 16.1%",
              "steps": [
                "पी (डी) = 0.02, पी (डी नाही) = 0.98",
                "पी (+ |D) = 0.95, पी (+ |no डी) = 0.10",
                "पी (+) = 0.95 × 0.02 + 0.10 × 0.98 = 0.117",
                "पी (डी। +) = 0.95 × 0.02/0.117 ≈ 0.162"
              ]
            }
          ],
          "quiz": [
            {
              "question": "जर अ आणि ब स्वतंत्र असतील तर पी (A|B) म्हणजे काय?",
              "options": [
                "पी (ए)",
                "पी (बी)",
                "पी (ए) × पी (बी)",
                "0."
              ],
              "correctAnswer": 0,
              "explanation": "स्वतंत्र असल्यास, ब जाणून घेतल्याने अः पी (A|B) = पी (ए) ची संभाव्यता बदलत नाही."
            },
            {
              "question": "गणना करण्यासाठी बेयस प्रमेय वापरले जातेः",
              "options": [
                "पी (ए) पासून पी (बी)",
                "पी पासून पी (A|B) (B|A)",
                "पी (ए ≤ बी) पासून पी (ए ≤ बी)",
                "वार (एक्स) पासून ई [एक्स]"
              ],
              "correctAnswer": 1,
              "explanation": "बेयस प्रमेय-पी (A|B) = पी (B|A) पी (ए)/पी (बी)-सशर्त उलट्या"
            },
            {
              "question": "कार्यक्रमांमधील वेळेचे कोणते वितरण मॉडेल?",
              "options": [
                "द्विपदी",
                "पॉइसन",
                "घातांकीय",
                "सामान्य."
              ],
              "correctAnswer": 2,
              "explanation": "घातांकीय वितरण मॉडेल पुढील घटना होईपर्यंत सतत वेळ"
            },
            {
              "question": "सामान्य वितरणामध्ये, 2 मानक विचलनांमध्ये किती टक्के डेटा असतो?",
              "options": [
                "68 टक्के",
                "95 टक्के",
                "99.7%",
                "90 टक्के"
              ],
              "correctAnswer": 1,
              "explanation": "68-95-99.7 नियमः 95 टक्के सरासरीच्या 2 सी. एम. च्या आत"
            }
          ]
        }
      },
      {
        "id": "4",
        "title": "सांख्यिकी-डेटा विश्लेषण आणि पूर्वकल्पना चाचणी",
        "description": "मास्टर सांख्यिकीय अनुमान, आत्मविश्वास अंतर आणि ए/बी चाचणी",
        "estimatedTime": "85 मिनिटे",
        "difficulty": "मध्यवर्ती",
        "content": {
          "overview": "सांख्यिकी कच्च्या डेटाचे अंतर्दृष्टीत रूपांतर करते. एम. एल. मध्ये, आम्ही वैशिष्ट्य अभियांत्रिकी, मॉडेल मूल्यांकन आणि डेटा-चालित निर्णय घेण्यासाठी आकडेवारी वापरतो. * * हे का महत्त्वाचे आहेः * * सांख्यिकीय चाचण्यांसह मॉडेल कामगिरीचे मूल्यांकन करा. ए/बी चाचणी बदल महत्त्वपूर्ण आहेत की नाही हे निर्धारित करते. आत्मविश्वास अंतर अनिश्चिततेचे प्रमाण निश्चित करते. वैशिष्ट्य निवड परस्परसंबंध विश्लेषणाचा वापर करते",
          "keyPoints": [
            "मीन, मिडियन, मोड मध्यवर्ती प्रवृत्तीचे वर्णन करतात",
            "भिन्नता आणि मानक विचलन उपाय प्रसार",
            "परस्परसंबंध हे चलांमधील संबंध दर्शविते",
            "पूर्वकल्पना चाचणी सांख्यिकीय महत्त्व निर्धारित करते",
            "पी-मूल्य <0.05 म्हणजे सामान्यतः लक्षणीय परिणाम",
            "आत्मविश्वासाचे अंतर वाजवी मूल्यांची श्रेणी प्रदान करते"
          ],
          "realWorldUseCases": {
            "abTesting": {
              "title": "संकेतस्थळ ऑप्टिमायझेशनसाठी ए/बी चाचणी",
              "description": "नवीन रचना रूपांतरण दर वाढवते का ते ठरवा",
              "input": "आवृत्ती अः 1000 भेटी, 50 रूपांतरणे। आवृत्ती बः 1000 भेटी, 65 रूपांतरणे",
              "output": "पी-मूल्य = 0.003 → लक्षणीय सुधारणा",
              "math": "दोन-नमुना प्रमाण चाचणीः झेड = (पी 1-पी 2)/एसई",
              "impact": "गुगल, अमेझॉन, मेटा येथे अब्जावधी डॉलर्सचे निर्णय"
            },
            "qualityControl": {
              "title": "उत्पादन गुणवत्ता नियंत्रण",
              "description": "उत्पादन प्रक्रिया बदलली आहे का ते शोधा",
              "input": "नमुना सरासरी = 100.5, ऐतिहासिक सरासरी = 100",
              "output": "नियंत्रण मर्यादेत → प्रक्रिया ठीक",
              "math": "नियंत्रण तक्ताः μ ± 3σ सीमा",
              "impact": "सदोष उत्पादने टाळा, कचरा कमी करा"
            },
            "clinicalTrials": {
              "title": "औषधांच्या कार्यक्षमतेची चाचणी",
              "description": "प्लेसीबोपेक्षा नवीन औषध चांगले असल्याचे सिद्ध करा",
              "input": "उपचार गट विरुद्ध नियंत्रण गट परिणाम",
              "output": "पी <0.001 → औषध प्रभावी आहे",
              "math": "टी-चाचणीः टी = (x 1-x 2)/एसई",
              "impact": "एफ. डी. ए. च्या मंजुरीसाठी सांख्यिकीय महत्त्व आवश्यक आहे"
            },
            "featureSelection": {
              "title": "एम. एल. वैशिष्ट्याचे महत्त्व विश्लेषण",
              "description": "कोणती वैशिष्ट्ये लक्ष्याचा अंदाज लावतात ते ओळखा",
              "input": "100 वैशिष्ट्ये, 10,000 नमुने",
              "output": "पी <0.01 सह शीर्ष 10 वैशिष्ट्ये",
              "math": "सहसंबंध गुणांकः r = cov (X, Y)/(σxσγ)",
              "impact": "प्रतिकृतीची गुंतागुंत कमी करा, अर्थ लावण्यामध्ये सुधारणा करा"
            }
          },
          "mathematicalFoundations": [
            {
              "concept": "मीन (सरासरी)",
              "formula": "μ = (1/n) xi",
              "explanation": "सर्व मूल्यांची बेरीज करा आणि गणनेने विभाजित करा",
              "application": "सरासरी अंदाज त्रुटी, सरासरी प्रतिसाद वेळ"
            },
            {
              "concept": "भिन्नता.",
              "formula": "σ2 = (1/n) (xi-μ) 2",
              "explanation": "सरासरीपासून सरासरी वर्ग विचलन",
              "application": "अंदाजातील परिवर्तनशीलता, माहितीचा प्रसार मोजणे"
            },
            {
              "concept": "मानक विचलन",
              "formula": "σ = √ भिन्नता",
              "explanation": "भिन्नतेचे वर्गमूळ (डेटा सारखेच एकक)",
              "application": "सरासरी, बाह्य शोधापासूनचे विशिष्ट अंतर"
            },
            {
              "concept": "परस्परसंबंध",
              "formula": "r = cov (X, Y)/(σx × σγ)",
              "explanation": "रेषीय संबंध मोजणे (-1 ते + 1)",
              "application": "वैशिष्ट्य सहसंबंध, बहुकोणीयता शोध"
            },
            {
              "concept": "टी-सांख्यिकी",
              "formula": "t = (x â-μ0)/(s/ρn)",
              "explanation": "गृहीत मूल्यापासून सॅम्पल मीनमध्ये किती मानक त्रुटी आहेत",
              "application": "दोन गटांची तुलना करा, गृहीतक चाचणी"
            },
            {
              "concept": "विश्वासाचा मध्यांतर",
              "formula": "सी. आय. = x â ±t * × (s/ρn)",
              "explanation": "X% विश्वासासह खरे मापदंड असलेली श्रेणी",
              "application": "95 टक्के सी. आय.: प्रयोग 100 वेळा पुनरावृत्ती केल्यास, 95 सी. आय. मध्ये खरे सरासरी असते."
            },
            {
              "concept": "पी-मूल्य",
              "formula": "पी (निरीक्षण माहिती। एच 0 खरे आहे)",
              "explanation": "शून्य गृहीतक खरे असल्यास परिणाम दिसण्याची संभाव्यता",
              "application": "पी <0.05: शून्य गृहीतक नाकारणे (5 टक्के महत्त्व पातळी)"
            }
          ],
          "statisticalTests": [
            {
              "name": "t-test",
              "purpose": "दोन गटांच्या साधनांची तुलना करा",
              "assumptions": "सामान्य वितरण, समान भिन्नता",
              "example": "कॅफीन चाचणीचे गुण सुधारते का?",
              "hypotheses": "एच 0: मायक्रॉन = मायक्रोन विरुद्ध एच 1: मायक्रोन = मायक्रोन"
            },
            {
              "name": "Chi-Square Test",
              "purpose": "श्रेणीबद्ध चलांच्या स्वातंत्र्याची चाचणी घ्या",
              "assumptions": "प्रत्येक पेशीमध्ये अपेक्षित वारंवारता ≤5",
              "example": "उत्पादनाच्या प्राधान्याशी लिंग संबंधित आहे का?",
              "hypotheses": "एच 0: स्वतंत्र चल विरुद्ध एच 1: संबंधित"
            },
            {
              "name": "ANOVA",
              "purpose": "3 + गटांच्या साधनांची तुलना करा",
              "assumptions": "गटांमध्ये सामान्य, समान फरक",
              "example": "3 शिकवण्याच्या पद्धती वेगवेगळे गुण देतात का?",
              "hypotheses": "एच 0: मायक्रॉन = मायक्रोन = मायक्रोन विरुद्ध एच 1: किमान एक फरक आहे."
            },
            {
              "name": "Correlation Test",
              "purpose": "परस्परसंबंध महत्त्वपूर्ण आहे का ते तपासा",
              "assumptions": "रेखीय संबंध, बायव्हेरिएट नॉर्मल",
              "example": "अभ्यासाच्या वेळेचा गुणांशी संबंध आहे का?",
              "hypotheses": "H0: ρ = 0 विरुद्ध H1: ρ ष्णू 0"
            }
          ],
          "codeExamples": [
            {
              "title": "वर्णनात्मक आकडेवारी",
              "language": "python",
              "explanation": "मध्यवर्ती प्रवृत्ती आणि प्रसाराची गणना करा",
              "code": "import numpy as np\nfrom scipy import stats\n\n# Sample data: exam scores\nscores = np.array([85, 92, 78, 95, 88, 76, 91, 84, 89, 93])\n\nprint(\"=== Descriptive Statistics ===\\n\")\n\n# Central Tendency\nprint(f\"Mean: {np.mean(scores):.2f}\")\nprint(f\"Median: {np.median(scores):.2f}\")\nprint(f\"Mode: {stats.mode(scores, keepdims=True).mode[0]}\")\n\n# Spread\nprint(f\"\\nVariance: {np.var(scores, ddof=1):.2f}\")\nprint(f\"Std Dev: {np.std(scores, ddof=1):.2f}\")\nprint(f\"Range: {np.ptp(scores)}\")\n\n# Percentiles\nprint(f\"\\n25th percentile: {np.percentile(scores, 25):.1f}\")\nprint(f\"75th percentile: {np.percentile(scores, 75):.1f}\")\nprint(f\"IQR: {stats.iqr(scores):.1f}\")",
              "realWorldExample": "ग्राहकांच्या खर्चाचे, प्रतिसादाच्या वेळेचे, प्रतिकृतीच्या अचूकतेचे विश्लेषण करा."
            },
            {
              "title": "पूर्वकल्पना चाचणी-टी चाचणी",
              "language": "python",
              "explanation": "सांख्यिकीदृष्ट्या दोन गटांची तुलना करा.",
              "code": "import numpy as np\nfrom scipy import stats\n\n# A/B test: old vs new website design\n# Metric: time on site (seconds)\nold_design = np.array([120, 135, 118, 142, 128, 131, 125, 138])\nnew_design = np.array([145, 152, 148, 160, 143, 155, 149, 158])\n\nprint(\"=== A/B Test: Two-Sample t-test ===\\n\")\n\n# Descriptive\nprint(f\"Old design: mean={old_design.mean():.1f}, std={old_design.std():.1f}\")\nprint(f\"New design: mean={new_design.mean():.1f}, std={new_design.std():.1f}\")\nprint(f\"Difference: {new_design.mean() - old_design.mean():.1f} seconds\")\n\n# t-test\nt_stat, p_value = stats.ttest_ind(new_design, old_design)\n\nprint(f\"\\nt-statistic: {t_stat:.4f}\")\nprint(f\"p-value: {p_value:.4f}\")\n\nalpha = 0.05\nif p_value < alpha:\n    print(f\"\\n✓ Result: SIGNIFICANT (p < {alpha})\")\n    print(\"  Reject null hypothesis: new design performs better\")\nelse:\n    print(f\"\\n✗ Result: NOT significant (p ≥ {alpha})\")\n    print(\"  Cannot conclude new design is better\")",
              "realWorldExample": "गुगल दरवर्षी हजारो ए/बी चाचण्या चालवते."
            },
            {
              "title": "आत्मविश्वासाचे अंतर",
              "language": "python",
              "explanation": "अंदाजांमधील अनिश्चिततेचे प्रमाण ठरवा",
              "code": "import numpy as np\nfrom scipy import stats\n\n# Customer satisfaction survey scores\nsurvey = np.array([7.2, 8.1, 6.9, 7.8, 8.5, 7.3, 8.0, 7.6, 8.2, 7.9])\n\nprint(\"=== 95% Confidence Interval ===\\n\")\n\nmean = np.mean(survey)\nstd_err = stats.sem(survey)  # Standard error\nconfidence = 0.95\n\n# t-distribution (unknown population std)\ndf = len(survey) - 1  # degrees of freedom\nt_crit = stats.t.ppf((1 + confidence) / 2, df)\n\nmargin_error = t_crit * std_err\nci_lower = mean - margin_error\nci_upper = mean + margin_error\n\nprint(f\"Sample mean: {mean:.2f}\")\nprint(f\"Standard error: {std_err:.3f}\")\nprint(f\"\\n95% CI: [{ci_lower:.2f}, {ci_upper:.2f}]\")\nprint(f\"\\nInterpretation: We are 95% confident the true\")\nprint(f\"population mean is between {ci_lower:.2f} and {ci_upper:.2f}\")",
              "realWorldExample": "राजकीय निवडणुका, गुणवत्ता मापन, आर्थिक अंदाज"
            },
            {
              "title": "परस्परसंबंधांचे विश्लेषण",
              "language": "python",
              "explanation": "चलांमधील संबंधांचे मापन करा",
              "code": "import numpy as np\nfrom scipy import stats\nimport matplotlib.pyplot as plt\n\n# Study hours vs exam score\nstudy_hours = np.array([2, 3, 5, 7, 8, 10, 12, 15, 18, 20])\nexam_score = np.array([55, 62, 70, 78, 82, 88, 91, 95, 97, 99])\n\nprint(\"=== Correlation Analysis ===\\n\")\n\n# Pearson correlation\nr, p_value = stats.pearsonr(study_hours, exam_score)\n\nprint(f\"Pearson correlation: r = {r:.4f}\")\nprint(f\"p-value: {p_value:.6f}\")\n\n# Interpret strength\nif abs(r) < 0.3:\n    strength = \"weak\"\nelif abs(r) < 0.7:\n    strength = \"moderate\"\nelse:\n    strength = \"strong\"\n\nprint(f\"\\nInterpretation: {strength} {'positive' if r > 0 else 'negative'} correlation\")\n\nif p_value < 0.05:\n    print(\"Correlation is statistically significant\")\nelse:\n    print(\"Correlation is NOT significant\")\n\n# Coefficient of determination\nr_squared = r ** 2\nprint(f\"\\nR² = {r_squared:.4f}\")\nprint(f\"{r_squared*100:.1f}% of variance in score explained by study hours\")",
              "realWorldExample": "वैशिष्ट्यांची निवड, बहुरेखीय शोध, ईडीए"
            }
          ],
          "practicalAssignments": [
            {
              "title": "ए/बी चाचणी गणक तयार करा",
              "difficulty": "मध्यम.",
              "estimatedTime": "45 मिनिटे",
              "description": "ए/बी चाचणी परिणामांचे सांख्यिकीय कठोरतेने विश्लेषण करण्यासाठी साधन तयार करा",
              "tasks": [
                "इनपुटः ए आणि बी साठी अभ्यागत आणि रूपांतरणे",
                "रूपांतरण दर आणि फरकाची गणना करा",
                "दोन-प्रमाण झेड-चाचणी करा",
                "पी-मूल्य आणि आत्मविश्वास कालावधीची गणना करा",
                "त्रुटी पट्ट्यांसह परिणामांची कल्पना करा",
                "80 टक्के विजेसाठी आवश्यक नमुना आकार निश्चित करा"
              ],
              "starterCode": "एस. सी. आय. पी. आयात आकडेवारी डी. एफ. ए. बी. टेस्ट (अभ्यागत _ ए, रूपांतरण _ ए, अभ्यागत _ बी, रूपांतरण _ बी, अल्फा = 0.05): \"\" रूपांतरण दरांवर ए/बी चाचणी करा. परतावाः रूपांतरण दर, पी-मूल्य, सी. आय., निष्कर्षासह ठरवा \"\" #टोडोः रूपांतरण दराची गणना करा #टोडोः झेड-चाचणीसाठी एकत्रित प्रमाण #टोडोः मानक त्रुटी #टोडोः झेड-सांख्यिकी आणि पी-मूल्य #टोडोः फरकासाठी आत्मविश्वास मध्यांतर #टोडोः परतावा संरचित परिणाम पास #उदाहरणेः वेबसाइट रीडिझाइन #एः 10000 अभ्यागत, 500 रूपांतरणे (5.0%) #बीः 10000 अभ्यागत, 580 रूपांतरणे (5.8%) #बी लक्षणीयरीत्या चांगले आहे का?",
              "expectedOutput": "पी-मूल्य <0.05 → होय, बी 95 टक्के आत्मविश्वासाने लक्षणीयरीत्या चांगले आहे"
            },
            {
              "title": "वैशिष्ट्य सहसंबंध विश्लेषण",
              "difficulty": "सोपी.",
              "estimatedTime": "35 मिनिटे",
              "description": "महत्त्वाची वैशिष्ट्ये ओळखण्यासाठी डेटासेटमधील परस्परसंबंधांचे विश्लेषण करा",
              "tasks": [
                "डेटासेट लोड करा (उदाहरणार्थ, बुबुळ, गृहनिर्माण)",
                "परस्परसंबंध मॅट्रिक्सची गणना करा",
                "उष्माचित्र दृश्य तयार करा",
                "अत्यंत परस्परसंबंधित जोड्या ओळखा (|r।> 0.7)",
                "प्रत्येक परस्परसंबंधाचे महत्त्व तपासा",
                "लक्ष्याशी संबंधित शीर्ष 5 वैशिष्ट्यांचा अहवाल द्या"
              ],
              "starterCode": "आयात नंपी म्हणून एन. पी. आयात पांडा म्हणून पी. डी. स्कायपी आयात आकडेवारीतून आयात सीबॉर्न म्हणून एस. एन. एस. म्हणून आयात करा #टोडोः लोड डेटासेट #टोडोः कॉम्प्युट कोरिलेशन मॅट्रिक्स #टोडोः सीबॉर्नसह हीटमॅप तयार करा #टोडोः पी-व्हॅल्यू <0.05 #टोडोसह सहसंबंध शोधाः मल्टीकोलिनियरिटी समस्या ओळखा",
              "expectedOutput": "सहसंबंध मॅट्रिक्स हीटमॅप + लक्षणीय सहसंबंधांची यादी"
            }
          ],
          "videoResources": [
            {
              "title": "स्टॅटक्वेस्ट-पूर्वकल्पना चाचणी",
              "url": "https://www.youtube.com/watch?v=0oc49DyA3hU",
              "duration": "12 मिनिटे",
              "description": "पी-मूल्ये आणि महत्त्व यांचे स्पष्ट स्पष्टीकरण"
            },
            {
              "title": "खान अकादमी-आत्मविश्वासाचे अंतर",
              "url": "https://www.khanacademy.org/math/statistics-probability/confidence-intervals-one-sample",
              "duration": "25 मिनिटे",
              "description": "सी. आय. चा अर्थ लावण्यासाठी संपूर्ण मार्गदर्शक"
            },
            {
              "title": "3 ब्ल्यू1-ब्राऊन-बेयस प्रमेय",
              "url": "https://www.youtube.com/watch?v=HZGCoVF3YvM",
              "duration": "15 मिनिटे",
              "description": "सांख्यिकीय अनुमानाचे दृश्य स्पष्टीकरण"
            }
          ],
          "cheatSheet": {
            "descriptive": [
              "अर्थः μ = σx/n-सरासरी",
              "मध्यमः क्रमवारी लावल्यास मध्यम मूल्य",
              "मोडः सर्वाधिक वारंवार मूल्य",
              "फरकः σ2 =  निष्पन्न (x-μ) 2/n-पसरवा",
              "एस. टी. डी. देवः σ = √ भिन्नता",
              "आय. क्यू. आर.: क्यू 3-क्यू 1-मजबूत प्रसार उपाय"
            ],
            "inferential": [
              "टी-चाचणीः दोन पद्धतींची तुलना करा",
              "अनोवाः तुलना करा 3 + म्हणजे",
              "ची-चौरसः श्रेणीबद्ध संघटना",
              "सहसंबंधः रेषीय संबंधांची ताकद",
              "पी-मूल्य <0.05: सांख्यिकीयदृष्ट्या महत्त्वपूर्ण",
              "95% सी. आय.: x ± 1.96 × एस. ई. (मोठे एन)"
            ]
          },
          "commonPitfalls": [
            {
              "mistake": "कार्यकारणभावासह गोंधळात टाकणारा परस्परसंबंध",
              "example": "आइस्क्रीमच्या विक्रीचा बुडून होणाऱ्या मृत्यूंशी संबंध",
              "fix": "परस्परसंबंध हे कारण दर्शवत नाही (गोंधळात टाकणारेः उन्हाळ्यातील उष्णता)"
            },
            {
              "mistake": "पी-हॅकिंगः पी <0.05 पर्यंत चाचणी",
              "example": "20 भिन्न मेट्रिक्स वापरून पहा, एक योगायोगाने महत्त्वपूर्ण ठरेल",
              "fix": "गृहीतकांची पूर्व-नोंदणी करा, अनेक तुलनांसाठी योग्य"
            },
            {
              "mistake": "नमुना आकाराकडे दुर्लक्ष करत आहे",
              "example": "लहान नमुना'लक्षणीय'परिणाम दर्शवू शकतो जो अर्थपूर्ण नाही",
              "fix": "परिणामाचा आकार आणि आत्मविश्वास अंतर देखील तपासा"
            },
            {
              "mistake": "तिरकस माहितीसाठी सरासरी वापरणे",
              "example": "उत्पन्न, घरांच्या किमती अतिशय अपवादात्मक आहेत",
              "fix": "तिरकस वितरणासाठी मध्यक वापरा"
            }
          ],
          "tipsAndTricks": [
            "सांख्यिकीय चाचण्यांपूर्वी नेहमी माहितीची कल्पना करा",
            "टी-चाचणीपूर्वी गृहितके तपासा (सामान्यता, समान भिन्नता)",
            "तिरकस माहितीसाठी मध्यम/आय. क्यू. आर. वापरा, सामान्य माहितीसाठी मध्यम/एस. टी. डी.",
            "केवळ पी-मूल्ये नव्हे, तर विश्वासार्ह अंतरांचा अहवाल द्या",
            "परिणामाचा आकार महत्त्वाचेः सांख्यिकीयदृष्ट्या महत्त्वपूर्ण व्यवहारात महत्वाचे",
            "शक्ती विश्लेषणः प्रयोगापूर्वी आवश्यक नमुना आकाराची गणना करा"
          ],
          "interactiveExercises": [
            {
              "type": "calculation",
              "question": "माहितीः [10,12,15,18,20]. सरासरी आणि मानक विचलनाची गणना करा.",
              "hint": "मीन = बेरीज/n, StdDev = σ (x-α) 2/n)",
              "solution": "मीन = 15, एसटीडीदेव = 3.74",
              "steps": [
                "मीन = (10+12 + 15+18 + 20)/5 = 75/5 = 15",
                "विचलनः-5,-3,0,3,5",
                "वर्गवारीः 25,9,0,9,25",
                "भिन्नता = 68/5 = 13.6",
                "एस. टी. डी. देव = 13.6 = 3.69"
              ]
            },
            {
              "type": "interpretation",
              "question": "अ/ब चाचणीः पी-मूल्य = 0.08. α = 0.05 वर महत्त्वपूर्ण?",
              "hint": "पी-मूल्याची महत्त्व पातळीशी तुलना करा",
              "solution": "नाही, लक्षणीय नाही (0.08> 0.05)",
              "steps": [
                "α = 0.05 (5 टक्के महत्त्व पातळी)",
                "पी = 0.08> 0.05",
                "शून्य गृहीतक नाकारता येत नाही",
                "फरक सांख्यिकीयदृष्ट्या महत्त्वपूर्ण नाही"
              ]
            }
          ],
          "quiz": [
            {
              "question": "बाह्यरेषकांमुळे कोणत्या उपायावर सर्वाधिक परिणाम होतो?",
              "options": [
                "मध्यम",
                "अर्थ.",
                "मोड",
                "आयक्यूआर"
              ],
              "correctAnswer": 1,
              "explanation": "मीन सर्व मूल्ये वापरते, त्यामुळे आऊटलिअर्स ते लक्षणीयरीत्या बदलतात. मध्यम मजबूत आहे."
            },
            {
              "question": "पी-मूल्य = 0.003 म्हणजे काय?",
              "options": [
                "3 टक्के शक्यता गृहीतक खरे आहे",
                "शून्य गृहीतक खरे असल्यास माहिती दिसण्याची 3 टक्के शक्यता",
                "निकालावर 97 टक्के विश्वास",
                "3 टक्के त्रुटी दर"
              ],
              "correctAnswer": 1,
              "explanation": "जर H0 बरोबर असेल तर p-मूल्य ही माहिती पाहण्याची (किंवा अधिक तीव्र) संभाव्यता आहे."
            },
            {
              "question": "95 टक्के आत्मविश्वासाचा मध्यांतर [2.1, 3.8] म्हणजेः",
              "options": [
                "95 टक्के डेटा या श्रेणीत आहे.",
                "खरे मापदंड निश्चितपणे या श्रेणीत आहेत.",
                "जर आपण पुन्हा नमुने घेतले, तर 95 टक्के सी. आय. मध्ये खरे मापदंड असतील.",
                "आमच्या अंदाजात 5 टक्के त्रुटी आहे."
              ],
              "correctAnswer": 2,
              "explanation": "सी. आय. हे प्रक्रियेबद्दल आहेः पुनरावृत्ती केलेल्या नमुन्यांमधील 95 टक्के अंतरांमध्ये खरे मूल्य असते."
            },
            {
              "question": "सहसंबंध r =-0.85 सूचित करतेः",
              "options": [
                "कमकुवत नकारात्मक संबंध",
                "मजबूत नकारात्मक संबंध",
                "संबंध नाहीत.",
                "मध्यम दर्जाचे सकारात्मक संबंध"
              ],
              "correctAnswer": 1,
              "explanation": "|r।> 0.7 हा मजबूत परस्परसंबंध आहे, नकारात्मक चिन्ह उलट संबंध दर्शवते"
            }
          ]
        }
      }
    ]
  }
}